{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training data using Labelbox\n",
    "* Download images and animal annotations\n",
    "* Upload them to labelbox using MAL\n",
    "* Label to add any missing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelbox import Client, Project, Dataset\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
    "from labelbox import LabelingFrontend\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "import uuid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images and Annotations\n",
    "* The dataset contains images of animals in the wild and corresponding bounding boxes\n",
    "* Read more about the dataset here: https://beerys.github.io/CaltechCameraTraps/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from here: https://beerys.github.io/CaltechCameraTraps/\n",
    "# This file is 6GB so this might take a little while\n",
    "if not os.path.exists('eccv_18_all_images_sm'):\n",
    "    !wget http://www.vision.caltech.edu/~sbeery/datasets/caltechcameratraps18/eccv_18_all_images_sm.tar.gz\n",
    "    !tar -zxf eccv_18_all_images_sm.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the annotations\n",
    "if not os.path.exists('eccv_18_annotation_files'):\n",
    "    !wget http://www.vision.caltech.edu/~sbeery/datasets/caltechcameratraps18/eccv_18_annotations.tar.gz\n",
    "    !tar -zxf eccv_18_annotations.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "* Select only day time images and a subset of possible animals\n",
    "* Since the images are coming from video frames we split into train and eval datasets to account for this.\n",
    "* Convert the data into a format that is compatible with labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('eccv_18_annotation_files/train_annotations.json'))\n",
    "data['categories'] = {d['id'] : d for d in data['categories']}\n",
    "annotations = defaultdict(lambda: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique sequence of frames so the that the same animal isn't in the train and eval set by chance\n",
    "#We also want different seq_ids so that they are all from different sequences (not same animal)\n",
    "\n",
    "images = {}\n",
    "ids = set()\n",
    "for img in data['images']:\n",
    "    if img['seq_id'] in ids:\n",
    "        continue\n",
    "    ids.add(img['seq_id'])\n",
    "    images[img['id']] = img\n",
    "data['images'] = images\n",
    "\n",
    "\n",
    "for annotation in data['annotations']:\n",
    "    if annotation.get('bbox') is None:\n",
    "        if annotation['image_id'] in data['images']:\n",
    "            del data['images'][annotation['image_id']]\n",
    "        continue\n",
    "    annotations[annotation['image_id']].append(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = {'dog', 'cat', 'deer', 'bobcat', 'fox'}\n",
    "\n",
    "\n",
    "def process_image(image, min_bbox_height_px = 50 , min_bbox_width_px = 50):\n",
    "    date_time_obj = datetime.datetime.strptime(image['date_captured'], '%Y-%m-%d %H:%M:%S')\n",
    "    if (not ((18 > date_time_obj.hour > 7)) or (date_time_obj.hour == 12)):\n",
    "        #Only train on day time images\n",
    "        return\n",
    "    \n",
    "    annots = annotations[image['id']]\n",
    "    im = None \n",
    "    box_coords = []\n",
    "    \n",
    "    for annot in annots:\n",
    "        if not (data['categories'][annot['category_id']]['name'] in target_classes):\n",
    "            return\n",
    "            \n",
    "        h, w = image['height'], image['width']\n",
    "        bbox = annot.get('bbox')\n",
    "        assert bbox is not None\n",
    "        \n",
    "        if bbox[0] < min_bbox_width_px or bbox[1] < min_bbox_height_px:\n",
    "            #Ignore tiny bboxes\n",
    "            return\n",
    "        \n",
    "        if (w - (bbox[0] + bbox[2])) < min_bbox_width_px or (h - (bbox[1] + bbox[3])) < min_bbox_height_px:\n",
    "            return \n",
    "        \n",
    "        if im is None:\n",
    "            im = np.array(Image.open(os.path.join('eccv_18_all_images_sm', image['file_name'])))\n",
    "            new_h, new_w = im.shape[:2]    \n",
    "            \n",
    "        scale = lambda x, y: (int((x / h) * new_h), int((y / w) * new_w))\n",
    "        start_pt = scale(bbox[0], bbox[1])\n",
    "        end_pt = scale(bbox[0] + bbox[2], bbox[1]+ bbox[3])\n",
    "        box_coords.append([start_pt, end_pt])\n",
    "    return im,box_coords, image['location']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n"
     ]
    }
   ],
   "source": [
    "examples = [process_image(ex) for ex in data['images'].values()]\n",
    "examples = [ex for ex in examples if ex is not None]\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write the data to file so that we can reference it later for uploads and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"uploaded_images\"):\n",
    "    os.mkdir(\"uploaded_images\")\n",
    "\n",
    "if not os.path.exists(\"labels\"): \n",
    "    os.mkdir(\"labels\")\n",
    "    \n",
    "image_paths = []\n",
    "for idx, example in enumerate(examples):\n",
    "    imm, coords, location = example\n",
    "    image_path = os.path.join(\"uploaded_images\", f\"{idx}.jpg\")\n",
    "    image_paths.append(image_path)\n",
    "    Image.fromarray(imm).save(image_path)\n",
    "    with open(os.path.join(\"labels\", f\"{idx}.json\"), 'w') as file:\n",
    "        file.write(json.dumps({'coords' : coords, 'location' : location}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Labelbox\n",
    "* Setup a project\n",
    "* Add the images to label\n",
    "* Upload annotations using MAL\n",
    "-----\n",
    "For more information on this process checkout the example notebooks covering mal:\n",
    "https://github.com/Labelbox/labelbox-python/tree/develop/examples#model-assisted-labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(api_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja2s0cTF2Z3djMHZwMDcwNHhoeDdtNHZrIiwib3JnYW5pemF0aW9uSWQiOiJja2s0cTF2Z2Fwc2F1MDczMjRhd25zanEyIiwiYXBpS2V5SWQiOiJja2t6bjd5dG5pZHNjMDcwNjczazIyamF1IiwiaWF0IjoxNjEyOTc0MjQ3LCJleHAiOjIyNDQxMjYyNDd9.GrGjHbN1w1X5-qLzlzp9UKCnkSffKqTQWEWIRyegHGg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = client.create_project(name = \"animal_demo_proj\")\n",
    "dataset = client.create_dataset(name = \"animal_demo_ds\")\n",
    "project.datasets.connect(dataset)\n",
    "dataset.create_data_rows(image_paths)\n",
    "project.enable_model_assisted_labeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = next(client.get_labeling_frontends(where=LabelingFrontend.name == \"Editor\"))\n",
    "\n",
    "\n",
    "ontology_builder = OntologyBuilder(tools=[\n",
    "    Tool(tool=Tool.Type.BBOX, name=\"person\"),\n",
    "    Tool(tool=Tool.Type.BBOX, name=\"animal\")\n",
    "])\n",
    "\n",
    "project.setup(editor, ontology_builder.asdict())\n",
    "\n",
    "# fetch ontology from api to get all of the ids\n",
    "ontology = ontology_builder.from_project(project)\n",
    "schema_lookup = {tool.name: tool.feature_schema_id for tool in ontology.tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(dr):\n",
    "    label_name = dr.external_id.split('/')[-1].replace('.jpg', '.json')\n",
    "    label_name = f\"labels/{label_name}\"\n",
    "    labels = json.load(open(label_name))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datarows = [dr for dr in list(project.datasets())[0].data_rows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "for datarow in datarows:\n",
    "    label = get_labels(datarow)['coords'][0]\n",
    "    row = {\n",
    "        'uuid' : str(uuid.uuid4()),\n",
    "        'schemaId' : schema_lookup['animal'],\n",
    "        'dataRow' : {'id' : datarow.uid},\n",
    "        'bbox' : {\n",
    "            'top' : label[0][1],\n",
    "            'left' : label[0][0],\n",
    "            'height' : label[1][1] - label[0][1],\n",
    "            'width' : label[1][0] - label[0][0]            \n",
    "        }\n",
    "    }\n",
    "    boxes.append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = project.upload_annotations(name = f\"upload-{uuid.uuid4()}\", annotations = boxes)\n",
    "upload.wait_until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go to labelbox and label\n",
    "* Most of the data is prelabeled so we just need to go through and make sure everything is correct\n",
    "* None of the people in the images have been labeled so we are also going to add those annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.labelbox.com/projects/ckq6zvmwm8sko0ya4fevdgsbf/overview\n"
     ]
    }
   ],
   "source": [
    "print(f\"https://app.labelbox.com/projects/{project.uid}/overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
