{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "korean-recall",
   "metadata": {},
   "source": [
    "## Annotation Types\n",
    "* This is a common format that we created to make the following easier:\n",
    "    1. Format conversion\n",
    "    2. ETL Pipelines\n",
    "    3. Training Models\n",
    "\n",
    "------\n",
    "* This is something we are actively developing. But at this moment we currently support:\n",
    "1. Core interfaces\n",
    "2. labelbox export format <-> annotation types\n",
    "3. labelbox prediction import format <-> annotation types\n",
    "\n",
    "(This is not currently compatible with tiled imagery.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-extension",
   "metadata": {},
   "source": [
    "### Core Interfaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-gasoline",
   "metadata": {},
   "source": [
    "The interfaces are designed to represent data for machine learning models.\n",
    "This means that you can use them without using labelbox or having references to labelbox objects. \n",
    "Functions for connecting annotations to labelbox are provided.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "protective-juice",
   "metadata": {},
   "source": [
    "Object Hierarchy:\n",
    "    - LabelCollection\n",
    "    - LabelGenerator\n",
    "        - Label\n",
    "            - data\n",
    "                - RasterData\n",
    "                - VideoData\n",
    "                - TextData\n",
    "            - annotations\n",
    "                - Metric\n",
    "                - ClassificationAnnotation                \n",
    "                - VideoClassificationAnnotation\n",
    "                    - Radio\n",
    "                    - Text\n",
    "                    - Checklist\n",
    "                    - Dropdown\n",
    "                - ObjectAnnotation\n",
    "                - VideoObjectAnnotation\n",
    "                    - Geometry\n",
    "                        - Point\n",
    "                        - Line\n",
    "                        - Mask\n",
    "                        - Rectangle\n",
    "                        - Polygon\n",
    "                    - NER\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-antique",
   "metadata": {},
   "source": [
    "These are usually built from the ground up:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic data\n",
    "from labelbox.data.annotation_types import (\n",
    "    LabelCollection,\n",
    "    Label,\n",
    "    RasterData,\n",
    "    TextData,\n",
    "    VideoData,\n",
    "    ObjectAnnotation,\n",
    "    ClassificationAnnotation,    \n",
    "    Polygon,\n",
    "    Rectangle,\n",
    "    Line,\n",
    "    Mask,\n",
    "    Point,\n",
    "    Checklist,\n",
    "    Radio,\n",
    "    Text,\n",
    "    ClassificationAnswer\n",
    ")\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from shapely.ops import transform\n",
    "from shapely.affinity import affine_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-arena",
   "metadata": {},
   "source": [
    "# Data \n",
    "* There are three classes to represent data\n",
    "    * TextData\n",
    "    * VideoData\n",
    "    * RasterData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-herald",
   "metadata": {},
   "source": [
    "### Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data can be instantiated with any of the following\n",
    "image = RasterData(im_bytes = b'bytes')\n",
    "image = RasterData(arr = np.zeros((10,10)).astype(np.uint8))\n",
    "image = RasterData(file_path = '/tmp/img.jpg')\n",
    "image_url = \"https://picsum.photos/id/1003/200/300\"\n",
    "image = RasterData(url = image_url)\n",
    "# All of these can access the numpy representation the same way:\n",
    "np_data = image.data\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "One valid object representation that breaks this pattern is:\n",
    "    data = RasterData(uid = \"some label cuid\")\n",
    "\n",
    "Support for this needs to be implemented for all data!!!!!!!\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# We can see the numpy version of our url\n",
    "\n",
    "im = Image.fromarray(np_data)\n",
    "im.resize((im.size[0]//2, im.size[1]//2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-profile",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text has the same access pattern as imagery.\n",
    "text = TextData(file_path = \"/tmp/some local file.txt\")\n",
    "text = TextData(text = \" some text content...\")\n",
    "text = TextData(url = \"https://filesamples.com/samples/document/txt/sample3.txt\")\n",
    "\n",
    "print(text.data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-concern",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerMeltdowns.mp4\"\n",
    "\n",
    "video = VideoData(file_path = \"some video path.mp4\")\n",
    "video = VideoData(frames = { 1: np.zeros((32, 32, 3), dtype = np.uint8)})\n",
    "video = VideoData(url=video_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "for idx, frame in video.frame_generator():\n",
    "    if idx % 50 == 0:\n",
    "        video_im = Image.fromarray(frame)\n",
    "        w,h = video_im.size\n",
    "        IPython.display.display( im.resize((w//16, h//16) ))        \n",
    "    if idx > 250:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-owner",
   "metadata": {},
   "source": [
    "### Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-swimming",
   "metadata": {},
   "source": [
    "#### Adding data row information\n",
    "* This is not required ( and can be added at a later time but you can add data row information to your data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TextData(text = \"some text\", uid = \"ckrey6o07000008l50uk2gcr3\", external_id = \"my_text_data_row\")\n",
    "rd = RasterData(url = image_url, uid = \"ckrey7te2000108l5hl8564dr\", external_id = \"my_raster_data_row\")\n",
    "vd = VideoData(url = video_url, uid = \"ckrey7xef000208l57hwfgi3v\", external_id = \"my_video_data_row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-beach",
   "metadata": {},
   "source": [
    "# TODO: Add apply to all function for label so users don't need to set this themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge cases:\n",
    "# If your remote data isn't stored as a signed url or publicly accessible there is a workaround.\n",
    "# Define a fetching function\n",
    "\n",
    "# Eg. the following if you need headers:\n",
    "#image.fetch_remote = lambda self: requests.get(self.url, headers = {...}).content\n",
    "# Or even accessing data from s3 if you did RasterData(url = \"s3://some s3 uri\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-portugal",
   "metadata": {},
   "source": [
    "# Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-workshop",
   "metadata": {},
   "source": [
    "* Create an annotation by providing the following:\n",
    "1. Value\n",
    "    - Must be either a Geometry, TextEntity, or Classification\n",
    "    - This is the same as a top level tool in labelbox\n",
    "2. name or schema_id\n",
    "    - This is the id that corresponds to a particular class or just simply the class name\n",
    "    - If uploading to labelbox this must match a field in an ontology.\n",
    "3. (Optional) Classifications \n",
    "    - List of ClassificationAnnotations. This self referencing field enables infinite nesting of classifications.\n",
    "    - Be careful with how you use the tool. Labelbox does not support nesting classifications\n",
    "    - E.g. you can have tool.classifications but not tool.classifications[0].classifications\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-escape",
   "metadata": {},
   "source": [
    "### ObjectAnnotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given some polygon:\n",
    "xy_poly = [[60.215, 160.706], [67.135, 176.513], [76.36, 180.136], [76.69, 222.287], [81.632, 245.668], [77.678, 291.442],\n",
    " [72.077, 300], [86.904, 300], [94.482, 243.692], [103.378, 243.363], [100.413, 269.378], [90.199, 289.795],\n",
    " [95.141, 296.381], [103.708, 292.43], [107.662, 271.683], [110.957, 300], [121.171, 299.675], [117.217, 243.692], [127.761, 236.118],\n",
    " [132.703, 298.028], [142.258, 297.369], [136.657, 249.949], [145.553, 207.797], [137.975, 185.075],\n",
    " [120.182, 180.465], [105.026, 189.356], [111.616, 161.694], [92.835, 155.767], [72.077, 160.048]]\n",
    "\n",
    "\n",
    "annotation = ObjectAnnotation(\n",
    "            value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "            name = \"deer\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 2. All Geometry annotations have the same set of useful functions:\n",
    "- raster()\n",
    "- shapely\n",
    "- geometry\n",
    "\n",
    "\"\"\"\n",
    "# Geojson\n",
    "print(annotation.value.geometry)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acute-alarm",
   "metadata": {},
   "source": [
    "Flip because shapely origin is different from image coords\n",
    "\n",
    "\n",
    "      Shapely Coordinates           Image Coordinates\n",
    "           ------                        -------\n",
    "    \n",
    "                               0 → → → Greater X → → →\n",
    "    ↑                          ↓\n",
    "    ↑                          ↓\n",
    "Greater Y                      ↓\n",
    "    ↑                       Greater Y\n",
    "    ↑                          ↓\n",
    "    ↑                          ↓\n",
    "    0 → → → Greater X → → →\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_y_axis(poly, height):\n",
    "    return affine_transform(poly,[1, 0, 0, -1, 0, height])\n",
    "\n",
    "\n",
    "flip_y_axis(annotation.value.shapely, im.size[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 255\n",
    "np_mask = annotation.value.raster(height = im.size[1], width = im.size[0], color = color)\n",
    "Image.fromarray(np_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another cool thing is if you have a mask object you can convert it back to a polygon:\n",
    "# Multiple Mask annotations can share a single RasterData reference.\n",
    "# The color is used to indicate whether or not those objects are the same class.\n",
    "mask_annotation = Mask(\n",
    "    mask = RasterData(arr = np_mask),\n",
    "    color = color \n",
    ")\n",
    "\n",
    "flip_y_axis(mask_annotation.shapely, im.size[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is the same polygon but with extra vertices. We can also simplify it:\n",
    "flip_y_axis(mask_annotation.shapely, im.size[1]).simplify(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition to masks and polygons we also support:\n",
    "\n",
    "point = Point(x = 5, y = 5)\n",
    "\n",
    "# Start is the top left coordinate\n",
    "# End is the bottom right coordinate\n",
    "rectangle = Rectangle(start = Point(x = 0, y = 5), end = Point(x = 5, y = 10))\n",
    "\n",
    "# Polyline, (can have more than two points)\n",
    "line = Line(points = [Point(x = 0, y = 0), Point(x = 1, y = 1), Point(x = 2, y = 1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-touch",
   "metadata": {},
   "source": [
    "### Classification Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_annotation = ClassificationAnnotation(\n",
    "    name = \"my text class\", \n",
    "    value = Text(answer = \"some text answer\")                               \n",
    ")\n",
    "\n",
    "# It is also valid to provide a schema_id instead of the name\n",
    "\n",
    "text_annotation = ClassificationAnnotation(\n",
    "    schema_id = \"my text class\", \n",
    "    value = Text(answer = \"some text answer\")                               \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Answers can either be defined by a schema id or just the value\n",
    "# If uploading to labelbox the schema_id must be value or the value must match a classifiation name in the ontology.\n",
    "radio_annotation = ClassificationAnnotation(\n",
    "    name = \"is dog\",\n",
    "    value = Radio(answer = ClassificationAnswer(name = \"dog\")) \n",
    ")\n",
    "\n",
    "\n",
    "radio_annotation = ClassificationAnnotation(\n",
    "    schema_id = \"ckresqdg7000001jnb70v4zcc\",\n",
    "    value = Radio(answer = ClassificationAnswer(schema_id = \"ckrdy06ia000007ky94h04qlj\")) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check list supports a list of AnnotationAnswers\n",
    "checklist_annotation = ClassificationAnnotation(\n",
    "    schema_id = \"ckrestd5g000101jnhudjf29a\",\n",
    "    value = Checklist(answer = [ClassificationAnswer(schema_id = \"ckrdy06ia000007ky94h04qlj\")])\n",
    ")\n",
    "                                \n",
    "checklist_annotation = ClassificationAnnotation(\n",
    "    name = \"weather\",\n",
    "    value = Checklist(answer = [ClassificationAnswer(name = \"cloudy\")]) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-defensive",
   "metadata": {},
   "source": [
    "### Nested Classifications\n",
    "\n",
    "* All classifications can be nested\n",
    "# TODO: Do we want to not support this since it doesn't align with labelbox?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annotation = ObjectAnnotation(\n",
    "            value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "            name = \"deer\",\n",
    "            classifications = [\n",
    "                checklist_annotation, radio_annotation\n",
    "            ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-fight",
   "metadata": {},
   "source": [
    "# Labels\n",
    "* Labels connect a list of annotations to data such as images, text, and video.\n",
    "* Labels have a convenient set of functions for dealing with that collection of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a label:\n",
    "label = Label(\n",
    "    data = RasterData(url = image_url),\n",
    "    annotations = [\n",
    "        ObjectAnnotation(\n",
    "            value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "            name = \"deer\"\n",
    "        ),\n",
    "        ObjectAnnotation(\n",
    "            name = \"deer_eyes\",\n",
    "            value = Mask(mask = RasterData(arr = np_mask), color = color)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-traffic",
   "metadata": {},
   "source": [
    "### Interacting with labelbox:\n",
    "* For this label to be compatible with labelbox we need the following:\n",
    "    - all named features must have schema_ids\n",
    "    - all data must have urls\n",
    "        - masks\n",
    "        - images\n",
    "        - videos\n",
    "        - text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelbox import Client\n",
    "client = Client(api_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3FjeDFkMDMwNjg0MHk2MWJvd2I1anI1Iiwib3JnYW5pemF0aW9uSWQiOiJja3FjeDFjem4wNjgzMHk2MWdoOXYwMmNzIiwiYXBpS2V5SWQiOiJja3JhdHhmajc0N2doMHk2NzBzZ3M4ZjNjIiwic2VjcmV0IjoiODk4N2U3ZDVhOGUzYWU1MjQzMDdiNzY5ODg0NTMzZGYiLCJpYXQiOjE2MjY3MTEzMzUsImV4cCI6MjI1Nzg2MzMzNX0.D3z3rM4dNyJkvzDaXSm0lKZWbe78DALfnOzDK8WRiLQ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-center",
   "metadata": {},
   "source": [
    "### Uploading Urls\n",
    "* It doesn't matter how urls are set\n",
    "* Manually setting urls or use helper functions are both valid for working with labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set just by adding a value:\n",
    "image = RasterData(arr = np_data)\n",
    "image.url = \"http://myurl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-samuel",
   "metadata": {},
   "source": [
    "* Use helper function:\n",
    "    - Upload image urls : `Label.add_url_to_data(signer)`\n",
    "    - Upload segmentation masks : `label.add_url_to_masks(signer)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signing_function(obj_bytes: bytes) -> str:\n",
    "    # Do not use this signer.. you will not be able to resign these images at a later date!!!\n",
    "    url = client.upload_data(content=obj_bytes, sign=True)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Create a function that groups geometries and draws them all on the same raster!!\n",
    "# Basically do this!\n",
    "xy_eye_polys = [\n",
    "    [[82, 180], [83, 184], [88, 184], [86, 180]],\n",
    "    [[97, 182], [99, 184], [102, 183], [101, 180], [98, 180]]\n",
    "]\n",
    "nose_poly = [[95, 192],\n",
    " [93, 197],\n",
    " [96, 198],\n",
    " [100, 197],\n",
    " [100, 194],\n",
    " [100, 192],\n",
    " [96, 192]\n",
    "]       \n",
    "# Prob provide a color mapping or something..\n",
    "h,w = np_data.shape[:2]\n",
    "eye_color = 255\n",
    "nose_color = 128\n",
    "eyes = [Polygon(points = [Point(x=x, y = y) for x,y in xy_eye_poly]) for xy_eye_poly in xy_eye_polys]\n",
    "eye_masks = np.max([eye.raster(height = h, width = w, color = eye_color) for eye in eyes], axis = 0)\n",
    "nose = Polygon(points = [Point(x=x, y = y) for x,y in nose_poly])\n",
    "nose_mask = nose.raster(height = h, width = w, color = nose_color)\n",
    "# Picks the brighter color if there is overlap. \n",
    "# If you don't want overlap then just simply create separate masks\n",
    "np_seg_mask = np.max([nose_mask, eye_masks], axis = 0)\n",
    "Image.fromarray(np_seg_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the signing function will not be invoked if urls are already set for these objects\n",
    "# Let's make a label:\n",
    "\n",
    "mask = RasterData(arr = np_seg_mask)\n",
    "\n",
    "eye_annotation = ObjectAnnotation(\n",
    "    name = \"deer_eyes\",\n",
    "    value = Mask(mask = mask, color = eye_color)\n",
    ")\n",
    "nose_annotation =   ObjectAnnotation(\n",
    "            name = \"deer_nose\",\n",
    "            value = Mask(mask = mask, color = nose_color),\n",
    "            classifications = [\n",
    "                ClassificationAnnotation(\n",
    "                    name = \"description\",\n",
    "                    value = Radio(\n",
    "                        answer = ClassificationAnswer(name = \"wet\")\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "deer_annotation = ObjectAnnotation(\n",
    "            value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "            name = \"deer\"\n",
    "        )\n",
    "\n",
    "classification = ClassificationAnnotation(name = \"image_description\", \n",
    "        value = Checklist(answer = [\n",
    "            ClassificationAnswer(name = \"bright\"),\n",
    "            ClassificationAnswer(name = \"not_blurry\"),            \n",
    "        ])\n",
    ")\n",
    "Image.fromarray(np.hstack([nose_annotation.value.raster(), eye_annotation.value.raster()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label = Label(\n",
    "    data = RasterData(arr = np_data),\n",
    "    annotations = [\n",
    "        deer_annotation, eye_annotation, nose_annotation, classification\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(label.data.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.add_url_to_data(signing_function)\n",
    "print(label.data.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also have a mask that needs a url:\n",
    "mask_annotations = [annot for annot in label.annotations if isinstance(annot.value, Mask)]\n",
    "for annot in mask_annotations:\n",
    "    print(annot.value.mask.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.add_url_to_masks(signing_function)\n",
    "# Note that these are the same mask but just have different colors for different classes.\n",
    "# The function only uploads one url! But saves a reference to each object\n",
    "for annot in mask_annotations:\n",
    "    print(annot.value.mask.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-capacity",
   "metadata": {},
   "source": [
    "### Creating Data Rows\n",
    "* Our Labels objects are great for working with locally but we might want to upload to labelbox\n",
    "* This is required for MAL, MEA, and to add additional labels to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.create_dataset(name = \"label_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the signing function is only used if a url is not already provided\n",
    "print(label.data.uid)\n",
    "label.create_data_row(dataset, signing_function)\n",
    "print(label.data.uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-spiritual",
   "metadata": {},
   "source": [
    "### Assigning Schema Ids:\n",
    "* All tools, classifications, and options either have names or schema_ids.\n",
    "* Locally it is convenient to provide a name so that we don't need a labelbox project to use these interfaces.\n",
    "* To use MAL and MEA schema ids are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When uploading for MAL or MEA we need an ontology.\n",
    "# So let's create one\n",
    "\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
    "from labelbox import LabelingFrontend\n",
    "\n",
    "# These names have to match our object names exactly!!\n",
    "ontology_builder = OntologyBuilder(tools=[\n",
    "    Tool(tool=Tool.Type.POLYGON, name=\"deer\"),\n",
    "    Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_nose\", \n",
    "         classifications = [\n",
    "             Classification(\n",
    "                 class_type = Classification.Type.RADIO, \n",
    "                 instructions = \"description\", \n",
    "                 options = [Option(value = \"wet\")]\n",
    "             )]),\n",
    "    Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_eyes\")    \n",
    "], classifications = [\n",
    "    Classification(\n",
    "        Classification.Type.CHECKLIST, \n",
    "        instructions = \"image_description\", \n",
    "        options = [Option(value = \"bright\"), Option(value = \"not_blurry\"), Option(value = \"dark\")])])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "editor = next(\n",
    "    client.get_labeling_frontends(where=LabelingFrontend.name == \"Editor\"))\n",
    "project = client.create_project(name=\"test_annotation_types\")\n",
    "project.setup(editor, ontology_builder.asdict())\n",
    "project.datasets.connect(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ontology ids from project\n",
    "ontology = OntologyBuilder.from_project(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label.assign_schema_ids(ontology)\n",
    "\n",
    "def show_schema_ids(label):\n",
    "    for annotation in label.annotations:\n",
    "        print(f\"Object : {annotation.name} - {annotation.schema_id}\")\n",
    "        for classification in annotation.classifications:\n",
    "            print(f\"--- Subclass : {classification.name} - {classification.schema_id}\")\n",
    "            option = classification.value\n",
    "            print(f\"--- --- Options: {option.answer.name} - {option.answer.schema_id}\")\n",
    "\n",
    "        if isinstance(annotation, ClassificationAnnotation):\n",
    "            for option in annotation.value.answer:\n",
    "                print(f\"--- Options: {option.name} - {option.schema_id}\")\n",
    "show_schema_ids(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.assign_schema_ids(ontology)\n",
    "show_schema_ids(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-specific",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "* Annotation types should be thought of as low level interfaces\n",
    "* We are working on a set of tools to make most of what is covered in this notebook happen behind the scenes\n",
    "* Checkout other notebooks to see how to use higher level tools that are compatible with these interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-romania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-colombia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Make sure the error message for this isn't so bad...\n",
    "# Basically if the ObjectAnnotation is missing we get a terrible union error \n",
    "# Prob add our own validators to all unions...\n",
    "\n",
    "\n",
    "image_url = \"asdsads\"\n",
    "xy_poly = [[0,1], [1,2], [3,4]]\n",
    "label = Label(\n",
    "    \n",
    "    data = RasterData(url = image_url),\n",
    "    annotations = [\n",
    "\n",
    "            Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: data.data should work with just a data_row_id!!!!!. We just need to pass in a client or something.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create raster function on label\n",
    "# Move data functions to data objects\n",
    "# TODO: Create a create_from_shapely function to instantiate each geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Serialization function section:\n",
    "#    - Show that everything is a dict\n",
    "# Talk about how great pydantic is. e.g. .dict() .json() .schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO: Does MAL support uploading grayscale images?\n",
    "# This needs to be tested with MAL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build ontology from annotation objects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
