{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increasing-operator",
   "metadata": {},
   "source": [
    "# Label Containers\n",
    "* There are two high level containers for labels\n",
    "    1. LabelList\n",
    "    2. LabelGenerator\n",
    "* Tools that are built to convert between formats, help with etl, and model training all will operate on these containers\n",
    "* Make sure to read basics. Explanations are not repeated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stuffed-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import labelbox\n",
    "except: \n",
    "    !git clone https://github.com/Labelbox/labelbox-python.git\n",
    "    !cd labelbox-python && git checkout ms/annotation-examples && pip install .[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sized-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelbox import Client\n",
    "from labelbox.data.annotation_types import LabelList, LabelGenerator\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
    "from labelbox import LabelingFrontend\n",
    "from labelbox.data.annotation_types import (\n",
    "    Label, \n",
    "    RasterData, \n",
    "    Mask, \n",
    "    Point, \n",
    "    Polygon, \n",
    "    ClassificationAnswer, \n",
    "    Radio, \n",
    "    Checklist, \n",
    "    ObjectAnnotation, \n",
    "    ClassificationAnnotation\n",
    ")\n",
    "import requests\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prerequisite-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't want to give google access to drive you can skip this cell\n",
    "# and manually set `API_KEY` below.\n",
    "COLAB = \"google.colab\" in str(get_ipython())\n",
    "if COLAB:\n",
    "    !pip install colab-env -qU\n",
    "    from colab_env import envvar_handler\n",
    "    envvar_handler.envload()\n",
    "\n",
    "API_KEY = os.environ.get(\"LABELBOX_API_KEY\")\n",
    "if not os.environ.get(\"LABELBOX_API_KEY\"):\n",
    "    API_KEY = getpass(\"Please enter your labelbox api key\")\n",
    "    if COLAB:\n",
    "        envvar_handler.add_env(\"LABELBOX_API_KEY\", API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extraordinary-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only update this if you have an on-prem deployment\n",
    "ENDPOINT = \"https://api.labelbox.com/graphql\"\n",
    "\n",
    "client = Client(api_key=API_KEY, endpoint=ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-burlington",
   "metadata": {},
   "source": [
    "#### Helper Functions\n",
    "* See annotation_type_basics for details on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fewer-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signing_function(obj_bytes: bytes) -> str:\n",
    "    # Do not use this signer. You will not be able to resign these images at a later date.\n",
    "    url = client.upload_data(content=obj_bytes, sign=True)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alive-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon():\n",
    "    # Given some polygon:\n",
    "    xy_poly = [\n",
    "        [60, 161], [67, 177], [76, 180], [77, 222], [82, 246], [78, 291], [72, 300], [87, 300], \n",
    "        [94, 244], [103, 243], [100, 269], [90, 290], [95, 296], [104, 292], [108, 272], \n",
    "        [111, 300], [121, 300], [117, 244], [128, 236], [133, 298], [142, 297], [137, 250], \n",
    "        [146, 208], [138, 185], [120, 180], [105, 189], [112, 162], [93, 156], [72, 160], \n",
    "    ]\n",
    "    return Polygon(points = [Point(x = x, y = y) for x,y in xy_poly])\n",
    "\n",
    "\n",
    "def get_labels():\n",
    "    im_h, im_w = 300, 200\n",
    "    image_url = \"https://picsum.photos/id/1003/200/300\"\n",
    "    nose_color, eye_color = (0,255,0), (255,0,0)\n",
    "    nose_mask = Point(x = 96, y = 194).raster(im_h, im_w, thickness = 3)\n",
    "    eye_masks = [\n",
    "         Point(x = 84, y = 182).raster(im_h, im_w, thickness = 3),\n",
    "        Point(x = 99, y = 181).raster(im_h, im_w, thickness = 3),\n",
    "    ]\n",
    "    mask_arr = np.max([*eye_masks,nose_mask] , axis = 0)\n",
    "    mask = RasterData(arr = mask_arr)\n",
    "    return [Label(\n",
    "        data = RasterData(im_bytes = requests.get(image_url).content),\n",
    "        annotations = [\n",
    "            ObjectAnnotation(value = get_polygon(),name = \"deer\"),\n",
    "            ObjectAnnotation(name = \"deer_eyes\", value = Mask(mask = mask, color = eye_color)),  \n",
    "            ObjectAnnotation(name = \"deer_nose\", value = Mask(mask = mask, color = nose_color),\n",
    "                classifications = [\n",
    "                    ClassificationAnnotation(\n",
    "                        name = \"nose_description\",\n",
    "                        value = Radio(\n",
    "                            answer = ClassificationAnswer(name = \"wet\")\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            ClassificationAnnotation(name = \"image_description\", value = Checklist(answer = [\n",
    "                ClassificationAnswer(name = \"bright\")\n",
    "            ]))\n",
    "        ]\n",
    "    )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "distant-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_schema_ids(label):\n",
    "    for annotation in label.annotations:\n",
    "        print(f\"Object : {annotation.name} - {annotation.schema_id}\")\n",
    "        for classification in getattr(annotation, 'classifications', []):\n",
    "            print(f\"--- Subclass : {classification.name} - {classification.schema_id}\")\n",
    "            option = classification.value\n",
    "            print(f\"--- --- Options: {option.answer.name} - {option.answer.schema_id}\")\n",
    "\n",
    "        if isinstance(annotation, ClassificationAnnotation):\n",
    "            for option in annotation.value.answer:\n",
    "                print(f\"--- Options: {option.name} - {option.schema_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "disciplinary-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_project():\n",
    "    # These names have to match our object names exactly!!\n",
    "    ontology_builder = OntologyBuilder(tools=[\n",
    "        Tool(tool=Tool.Type.POLYGON, name=\"deer\"),\n",
    "        Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_nose\", \n",
    "             classifications = [\n",
    "                 Classification(\n",
    "                     class_type = Classification.Type.RADIO, \n",
    "                     instructions = \"nose_description\", \n",
    "                     options = [Option(value = \"wet\")]\n",
    "                 )]),\n",
    "        Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_eyes\")    \n",
    "    ], classifications = [\n",
    "        Classification(\n",
    "            Classification.Type.CHECKLIST, \n",
    "            instructions = \"image_description\", \n",
    "            options = [Option(value = \"bright\"), Option(value = \"not_blurry\"), Option(value = \"dark\")])])\n",
    "\n",
    "    editor = next(\n",
    "        client.get_labeling_frontends(where=LabelingFrontend.name == \"Editor\"))\n",
    "    project = client.create_project(name=\"test_annotation_types\")\n",
    "    project.setup(editor, ontology_builder.asdict())\n",
    "    dataset = client.create_dataset(name = 'my_ds')\n",
    "    project.datasets.connect(dataset)\n",
    "\n",
    "    ontology = OntologyBuilder.from_project(project)\n",
    "    return ontology, dataset, project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "moved-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mask_urls(label):\n",
    "    for annotation in label.annotations:\n",
    "        if isinstance(annotation.value, Mask):\n",
    "            print(annotation.value.mask.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "processed-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_references(label):\n",
    "    print('\\n---  schema ids ---\\n')\n",
    "    show_schema_ids(label)\n",
    "    print(\"\\n--- mask urls ---\\n\")\n",
    "    print_mask_urls(label)\n",
    "    print('\\n--- image url ---\\n')\n",
    "    print(label.data.url)    \n",
    "    print('\\n--- data row reference ---\\n')\n",
    "    print(original_label.data.uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-ocean",
   "metadata": {},
   "source": [
    "# LabelList\n",
    "* This object is essentially a list of Labels with a set of helpful utilties\n",
    "* This object is simple and fast at the expense of memory\n",
    "    * Larger datasets shouldn't use label list ( or at least will require more ram ).\n",
    "* Why use label list over just a list of labels?\n",
    "    * Multithreaded utilities (faster)\n",
    "    * Compatible with converter functions (functions useful for translating between formats, etl, and training )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "trained-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels()\n",
    "label_list = LabelList(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-command",
   "metadata": {},
   "source": [
    "## Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cubic-lunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'labelbox.data.annotation_types.label.Label'>\n",
      "1\n",
      "<class 'labelbox.data.annotation_types.label.Label'>\n"
     ]
    }
   ],
   "source": [
    "# Iterable, behaves like a list\n",
    "for label in label_list:\n",
    "    print(type(label))\n",
    "# Get length\n",
    "print(len(label_list))\n",
    "# By index\n",
    "print(type(label_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-league",
   "metadata": {},
   "source": [
    "### Upload segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "senior-platform",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2F689e4c26-d397-b0ee-912f-01ed98597092-1?Expires=1627331194133&KeyName=labelbox-assets-key-3&Signature=ouNZBuB2Di38hIAEc2oqBXaCjJ4\n",
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2F689e4c26-d397-b0ee-912f-01ed98597092-1?Expires=1627331194133&KeyName=labelbox-assets-key-3&Signature=ouNZBuB2Di38hIAEc2oqBXaCjJ4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Add urls to all segmentation masks:\n",
    "# (in parallel)\n",
    "for label in label_list:\n",
    "    print_mask_urls(label)\n",
    "    \n",
    "label_list.add_url_to_masks(signing_function)\n",
    "\n",
    "for label in label_list:\n",
    "    print_mask_urls(label)\n",
    "# Again note that these all share the same segmentation mask\n",
    "# ( This is determined by the fact that they share the same reference )\n",
    "# This mask is only uploaded once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-tactics",
   "metadata": {},
   "source": [
    "### Create signed urls for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "shared-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2F99b31026-2cfc-1594-8d61-98330c953a52-1?Expires=1627331194575&KeyName=labelbox-assets-key-3&Signature=b_imojOA7K6yLU9qvFsoQkXiEgI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Add urls to all segmentation masks:\n",
    "# (in parallel)\n",
    "print(label_list[0].data.url)\n",
    "label_list.add_url_to_data(signing_function)\n",
    "print(label_list[0].data.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-miracle",
   "metadata": {},
   "source": [
    "### Add to labelbox dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "oriented-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next two sections we need an ontology and dataset\n",
    "ontology, dataset, project = setup_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "greatest-prediction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 1137.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckrjnjdqaualy0ypkbxnc8eh1\n"
     ]
    }
   ],
   "source": [
    "print(label_list[0].data.uid)\n",
    "# Note that this function will assign a uuid as the external id if it isn't provided.\n",
    "label_list.add_to_dataset(dataset, signing_function)\n",
    "print(label_list[0].data.uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-translation",
   "metadata": {},
   "source": [
    "### Add schema ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "quality-daughter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object : deer - None\n",
      "Object : deer_eyes - None\n",
      "Object : deer_nose - None\n",
      "--- Subclass : nose_description - None\n",
      "--- --- Options: wet - None\n",
      "Object : image_description - None\n",
      "--- Options: bright - None\n",
      "--------------------------------------------------\n",
      "Object : deer - ckrjnjc8sltga0y8u08nd4ta9\n",
      "Object : deer_eyes - ckrjnjc8sltge0y8ufgrm11sl\n",
      "Object : deer_nose - ckrjnjc8sltgc0y8u5wbi9bkf\n",
      "--- Subclass : nose_description - ckrjnjc9oltgm0y8ueemo7cbj\n",
      "--- --- Options: wet - ckrjnjcaaltgo0y8u97ze8y99\n",
      "Object : image_description - ckrjnjc8rltg80y8u19aghqcy\n",
      "--- Options: bright - ckrjnjc9kltgg0y8uce3u132y\n"
     ]
    }
   ],
   "source": [
    "for label in label_list:\n",
    "    show_schema_ids(label)\n",
    "# Note that this function will assign a uuid as the external id if it isn't provided.\n",
    "label_list.assign_schema_ids(ontology)\n",
    "print('-'* 50)\n",
    "for label in label_list:\n",
    "    show_schema_ids(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "collectible-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup:\n",
    "dataset.delete()\n",
    "project.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-auditor",
   "metadata": {},
   "source": [
    "# LabelGenerator\n",
    "* This object generates labels and provides a set of helpful utilties\n",
    "* This object is complex and slower than LabelList in order to be highly memory efficient\n",
    "    * Larger datasets should use label generators\n",
    "* Why use label generator over just a generator that yields labels?\n",
    "    * This object supports parallel io operations to buffer results in the background.\n",
    "    * Compatible with converter functions (functions useful for translating between formats, etl, and training )\n",
    "* The first qsize elements run serially from when the chained functions are added.\n",
    "    * After that iterating will get much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hidden-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels()\n",
    "label_generator = LabelGenerator(labels)\n",
    "ontology, dataset, project = setup_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "endangered-touch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran once\n"
     ]
    }
   ],
   "source": [
    "# So we can't show the before and afters because the generator is not repeatable\n",
    "\n",
    "try:\n",
    "    label = next(label_generator)\n",
    "    print(\"Ran once\")\n",
    "    label = next(label_generator)\n",
    "    print(\"Ran twice\")\n",
    "except StopIteration:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cellular-standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to index\n"
     ]
    }
   ],
   "source": [
    "# Does not support indexing ( it is a generator.. )\n",
    "try:\n",
    "    label_generator[0]\n",
    "    print(\"Can index\")\n",
    "except TypeError:\n",
    "    print(\"Unable to index\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-opportunity",
   "metadata": {},
   "source": [
    "### Functions to modify results\n",
    "* We can set functions to run on the result of the generator\n",
    "* Since these are run in background threads it is a lot faster than applying them on each label individually\n",
    "* The functions are lazily evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cooked-opera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---  schema ids ---\n",
      "\n",
      "Object : deer - None\n",
      "Object : deer_eyes - None\n",
      "Object : deer_nose - None\n",
      "--- Subclass : nose_description - None\n",
      "--- --- Options: wet - None\n",
      "Object : image_description - None\n",
      "--- Options: bright - None\n",
      "\n",
      "--- mask urls ---\n",
      "\n",
      "None\n",
      "None\n",
      "\n",
      "--- image url ---\n",
      "\n",
      "None\n",
      "\n",
      "--- data row reference ---\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Recreate because we already went through all of the items when we showed that it isn't repeatable\n",
    "original_label = labels[0]\n",
    "\n",
    "show_references(original_label)\n",
    "label_generator = LabelGenerator(labels) \\\n",
    "        .add_url_to_masks(signing_function) \\\n",
    "        .add_to_dataset(dataset, signing_function) \\\n",
    "        .assign_schema_ids(ontology)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "reliable-hughes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---  schema ids ---\n",
      "\n",
      "Object : deer - None\n",
      "Object : deer_eyes - None\n",
      "Object : deer_nose - None\n",
      "--- Subclass : nose_description - None\n",
      "--- --- Options: wet - None\n",
      "Object : image_description - None\n",
      "--- Options: bright - None\n",
      "\n",
      "--- mask urls ---\n",
      "\n",
      "None\n",
      "None\n",
      "\n",
      "--- image url ---\n",
      "\n",
      "None\n",
      "\n",
      "--- data row reference ---\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "show_references(original_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unable-vehicle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---  schema ids ---\n",
      "\n",
      "Object : deer - ckrjnjkgo0acl0y8d3jb03y44\n",
      "Object : deer_eyes - ckrjnjkgp0acp0y8d4qrh77hr\n",
      "Object : deer_nose - ckrjnjkgo0acn0y8datv48hq4\n",
      "--- Subclass : nose_description - ckrjnjkhf0acx0y8d5zrf0myf\n",
      "--- --- Options: wet - ckrjnjkhz0acz0y8dbmlp9moo\n",
      "Object : image_description - ckrjnjkgn0acj0y8de44k7ibe\n",
      "--- Options: bright - ckrjnjkha0acr0y8d173f2paz\n",
      "\n",
      "--- mask urls ---\n",
      "\n",
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2F9fad073e-3073-0ac3-9c13-176806f4d580-1?Expires=1627331208015&KeyName=labelbox-assets-key-3&Signature=zyBB8gaW76Np_-NdTnhkAjAhae0\n",
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2F9fad073e-3073-0ac3-9c13-176806f4d580-1?Expires=1627331208015&KeyName=labelbox-assets-key-3&Signature=zyBB8gaW76Np_-NdTnhkAjAhae0\n",
      "\n",
      "--- image url ---\n",
      "\n",
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2Ffdd6a888-90b8-2c23-e5fd-1c9294bfb8aa-1?Expires=1627331209063&KeyName=labelbox-assets-key-3&Signature=YjAhWZgw9nScHopBbmsohJLGvB4\n",
      "\n",
      "--- data row reference ---\n",
      "\n",
      "ckrjnjmnk0adk0y8d5b7kanr1\n"
     ]
    }
   ],
   "source": [
    "label = next(label_generator)\n",
    "show_references(original_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-blood",
   "metadata": {},
   "source": [
    "* Note that the first qsize elements run serially from when the chained functions are added.\n",
    "* After that iterating will get much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mounted-immunology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<labelbox.data.annotation_types.collection.LabelList at 0x1076ae400>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LabelGenerators can be converted to a LabelList\n",
    "LabelGenerator(labels).as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "quarterly-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.delete()\n",
    "project.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-hygiene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-merchandise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
