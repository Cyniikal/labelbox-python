{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stock-swing",
   "metadata": {},
   "source": [
    "# Label Containers\n",
    "* There are two high level containers for labels\n",
    "    1. LabelCollection\n",
    "    2. LabelGenerator\n",
    "* Tools that are built to convert between formats, help with etl, and model training all will operate on these containers\n",
    "* Make sure to read basics. Explanations are not repeated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "binary-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared resources:\n",
    "# See annotation_type_basics to understand this section\n",
    "\n",
    "from labelbox import Client\n",
    "from labelbox.data.annotation_types import LabelCollection, LabelGenerator\n",
    "\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
    "from labelbox import LabelingFrontend\n",
    "from labelbox.data.annotation_types import Label, RasterData, Mask, Point, Polygon, ClassificationAnswer, Radio, Checklist, ObjectAnnotation, ClassificationAnnotation\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "\n",
    "image_url = \"https://picsum.photos/id/1003/200/300\"\n",
    "\n",
    "client = Client()\n",
    "\n",
    "def signing_function(obj_bytes: bytes) -> str:\n",
    "    # Do not use this signer.. you will not be able to resign these images at a later date!!!\n",
    "    url = client.upload_data(content=obj_bytes, sign=True)\n",
    "    return url\n",
    "\n",
    "\n",
    "xy_eye_polys = [\n",
    "    [[82, 180], [83, 184], [88, 184], [86, 180]],\n",
    "    [[97, 182], [99, 184], [102, 183], [101, 180], [98, 180]]\n",
    "]\n",
    "nose_poly = [[95, 192],\n",
    " [93, 197],\n",
    " [96, 198],\n",
    " [100, 197],\n",
    " [100, 194],\n",
    " [100, 192],\n",
    " [96, 192]\n",
    "]       \n",
    "\n",
    "xy_poly = [[60.215, 160.706], [67.135, 176.513], [76.36, 180.136], [76.69, 222.287], [81.632, 245.668], [77.678, 291.442],\n",
    " [72.077, 300], [86.904, 300], [94.482, 243.692], [103.378, 243.363], [100.413, 269.378], [90.199, 289.795],\n",
    " [95.141, 296.381], [103.708, 292.43], [107.662, 271.683], [110.957, 300], [121.171, 299.675], [117.217, 243.692], [127.761, 236.118],\n",
    " [132.703, 298.028], [142.258, 297.369], [136.657, 249.949], [145.553, 207.797], [137.975, 185.075],\n",
    " [120.182, 180.465], [105.026, 189.356], [111.616, 161.694], [92.835, 155.767], [72.077, 160.048]]\n",
    "\n",
    "# Prob provide a color mapping or something..\n",
    "h,w = 300, 200\n",
    "eye_color = 255\n",
    "nose_color = 128\n",
    "eyes = [Polygon(points = [Point(x=x, y = y) for x,y in xy_eye_poly]) for xy_eye_poly in xy_eye_polys]\n",
    "eye_masks = np.max([eye.raster(height = h, width = w, color = eye_color) for eye in eyes], axis = 0)\n",
    "nose = Polygon(points = [Point(x=x, y = y) for x,y in nose_poly])\n",
    "nose_mask = nose.raster(height = h, width = w, color = nose_color)\n",
    "# Picks the brighter color if there is overlap. \n",
    "# If you don't want overlap then just simply create separate masks\n",
    "np_seg_mask = np.max([nose_mask, eye_masks], axis = 0)\n",
    "\n",
    "def get_labels():\n",
    "    mask = RasterData(arr = np_seg_mask )\n",
    "    return [Label(\n",
    "        data = RasterData(im_bytes = requests.get(image_url).content),\n",
    "        annotations = [\n",
    "            ObjectAnnotation(\n",
    "                value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "                name = \"deer\"\n",
    "            ),\n",
    "            ObjectAnnotation(\n",
    "                name = \"deer_eyes\",\n",
    "                value = Mask(mask = mask, color = eye_color)\n",
    "            ),  \n",
    "           ObjectAnnotation(\n",
    "                name = \"deer_nose\",\n",
    "                value = Mask(mask = mask, color = nose_color),\n",
    "                classifications = [\n",
    "                    ClassificationAnnotation(\n",
    "                        name = \"description\",\n",
    "                        value = Radio(\n",
    "                            answer = ClassificationAnswer(name = \"wet\")\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            ), ObjectAnnotation(\n",
    "                name = \"deer_nose\",\n",
    "                value = Mask(mask = mask, color = nose_color),\n",
    "                classifications = [\n",
    "                    ClassificationAnnotation(\n",
    "                        name = \"description\",\n",
    "                        value = Radio(\n",
    "                            answer = ClassificationAnswer(name = \"wet\")\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )]\n",
    "\n",
    "\n",
    "def show_schema_ids(label):\n",
    "    for annotation in label.annotations:\n",
    "        print(f\"Object : {annotation.name} - {annotation.schema_id}\")\n",
    "        for classification in annotation.classifications:\n",
    "            print(f\"--- Subclass : {classification.name} - {classification.schema_id}\")\n",
    "            option = classification.value\n",
    "            print(f\"--- --- Options: {option.answer.name} - {option.answer.schema_id}\")\n",
    "\n",
    "        if isinstance(annotation, ClassificationAnnotation):\n",
    "            for option in annotation.value.answer:\n",
    "                print(f\"--- Options: {option.name} - {option.schema_id}\")\n",
    "\n",
    "def setup_project():\n",
    "    # These names have to match our object names exactly!!\n",
    "    ontology_builder = OntologyBuilder(tools=[\n",
    "        Tool(tool=Tool.Type.POLYGON, name=\"deer\"),\n",
    "        Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_nose\", \n",
    "             classifications = [\n",
    "                 Classification(\n",
    "                     class_type = Classification.Type.RADIO, \n",
    "                     instructions = \"description\", \n",
    "                     options = [Option(value = \"wet\")]\n",
    "                 )]),\n",
    "        Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_eyes\")    \n",
    "    ], classifications = [\n",
    "        Classification(\n",
    "            Classification.Type.CHECKLIST, \n",
    "            instructions = \"image_description\", \n",
    "            options = [Option(value = \"bright\"), Option(value = \"not_blurry\"), Option(value = \"dark\")])])\n",
    "\n",
    "    editor = next(\n",
    "        client.get_labeling_frontends(where=LabelingFrontend.name == \"Editor\"))\n",
    "    project = client.create_project(name=\"test_annotation_types\")\n",
    "    project.setup(editor, ontology_builder.asdict())\n",
    "    dataset = client.create_dataset(name = 'my_ds')\n",
    "    project.datasets.connect(dataset)\n",
    "\n",
    "    ontology = OntologyBuilder.from_project(project)\n",
    "    return ontology, dataset, project\n",
    "\n",
    "def print_mask_urls(label):\n",
    "    for annotation in label.annotations:\n",
    "        if isinstance(annotation.value, Mask):\n",
    "            print(annotation.value.mask.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-sensitivity",
   "metadata": {},
   "source": [
    "# LabelCollection\n",
    "* This object is essentially a list of Labels with a set of helpful utilties\n",
    "* This object is simple and fast at the expense of memory\n",
    "    * Larger datasets shouldn't use label collections ( or at least will require more ram ).\n",
    "* Why use label collection over just a list of labels?\n",
    "    * Multithreaded utilities (faster)\n",
    "    * Compatible with converter functions (functions useful for translating between formats, etl, and training )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "demonstrated-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels()\n",
    "label_collection = LabelCollection(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-possession",
   "metadata": {},
   "source": [
    "## Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afraid-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'labelbox.data.annotation_types.label.Label'>\n",
      "1\n",
      "<class 'labelbox.data.annotation_types.label.Label'>\n"
     ]
    }
   ],
   "source": [
    "# Iterable, Acts like a list\n",
    "for label in label_collection:\n",
    "    print(type(label))\n",
    "# Get length\n",
    "print(len(label_collection))\n",
    "# By index\n",
    "print(type(label_collection[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-secretariat",
   "metadata": {},
   "source": [
    "### Upload segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disabled-practitioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2F90a848f5-2038-3d8f-e912-0ac34949a3a3-1?Expires=1627055774270&KeyName=labelbox-assets-key-3&Signature=cCgkDBIRsjWSYPe7JdRIBjgUyPs\n",
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2F90a848f5-2038-3d8f-e912-0ac34949a3a3-1?Expires=1627055774270&KeyName=labelbox-assets-key-3&Signature=cCgkDBIRsjWSYPe7JdRIBjgUyPs\n",
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2F90a848f5-2038-3d8f-e912-0ac34949a3a3-1?Expires=1627055774270&KeyName=labelbox-assets-key-3&Signature=cCgkDBIRsjWSYPe7JdRIBjgUyPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Add urls to all segmentation masks:\n",
    "# (in parallel)\n",
    "for label in label_collection:\n",
    "    print_mask_urls(label)\n",
    "    \n",
    "label_collection.add_url_to_masks(signing_function)\n",
    "\n",
    "for label in label_collection:\n",
    "    print_mask_urls(label)\n",
    "# Again note that these all share the same segmentation mask\n",
    "# ( This is determined by the fact that they share the same reference )\n",
    "# This mask is only uploaded once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-church",
   "metadata": {},
   "source": [
    "### Create signed urls for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "norwegian-sterling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.labelbox.com/ckqcx1czn06830y61gh9v02cs%2F3da0abde-b2f4-b453-e65f-589aad3c989f-1?Expires=1627055774638&KeyName=labelbox-assets-key-3&Signature=WkEwp5xanY5KBn9DdD5xlmm3S5k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Add urls to all segmentation masks:\n",
    "# (in parallel)\n",
    "print(label_collection[0].data.url)\n",
    "label_collection.add_url_to_data(signing_function)\n",
    "print(label_collection[0].data.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-hurricane",
   "metadata": {},
   "source": [
    "### Add to labelbox dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "threaded-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next two sections we need an ontology and dataset\n",
    "ontology, dataset, project = setup_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "weekly-illness",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 4293.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckrf3k6a85bxz0ytiew58btq7\n"
     ]
    }
   ],
   "source": [
    "print(label_collection[0].data.uid)\n",
    "# Note that this function will assign a uuid as the external id if it isn't provided.\n",
    "label_collection.add_to_dataset(dataset, signing_function)\n",
    "print(label_collection[0].data.uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-roman",
   "metadata": {},
   "source": [
    "### Add schema ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "genuine-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object : deer - None\n",
      "Object : deer_eyes - None\n",
      "Object : deer_nose - None\n",
      "--- Subclass : description - None\n",
      "--- --- Options: wet - None\n",
      "Object : deer_nose - None\n",
      "--- Subclass : description - None\n",
      "--- --- Options: wet - None\n",
      "--------------------------------------------------\n",
      "Object : deer - ckrf3k4pt7qbm0y9j40kf8v54\n",
      "Object : deer_eyes - ckrf3k4pu7qbq0y9jc91r6s16\n",
      "Object : deer_nose - ckrf3k4pt7qbo0y9j4eswgg80\n",
      "--- Subclass : description - ckrf3k4r27qc30y9j4wdph03x\n",
      "--- --- Options: wet - ckrf3k4rn7qc50y9j4xz68f5m\n",
      "Object : deer_nose - ckrf3k4pt7qbo0y9j4eswgg80\n",
      "--- Subclass : description - ckrf3k4r27qc30y9j4wdph03x\n",
      "--- --- Options: wet - ckrf3k4rn7qc50y9j4xz68f5m\n"
     ]
    }
   ],
   "source": [
    "for label in label_collection:\n",
    "    show_schema_ids(label)\n",
    "# Note that this function will assign a uuid as the external id if it isn't provided.\n",
    "label_collection.assign_schema_ids(ontology)\n",
    "print('-'* 50)\n",
    "for label in label_collection:\n",
    "    show_schema_ids(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "invalid-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup:\n",
    "dataset.delete()\n",
    "project.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-transition",
   "metadata": {},
   "source": [
    "# LabelGenerator\n",
    "* This object generates labels and provides a set of helpful utilties\n",
    "* This object is complex and slower than LabelCollections to be highly memory efficient\n",
    "    * Larger datasets should use label generators\n",
    "* Why use label generator over just a generator that yields labels?\n",
    "    * This object supports parallel io operations to buffer in the background.\n",
    "    * Compatible with converter functions (functions useful for translating between formats, etl, and training )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels()\n",
    "label_generator = LabelGenerator(labels)\n",
    "ontology, dataset, project = setup_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can't show the before and afters because the generator is not repeatable\n",
    "\n",
    "try:\n",
    "    \n",
    "    label = next(label_generator)\n",
    "    print(\"Ran once\")\n",
    "    label = next(label_generator)\n",
    "    print(\"Ran twice\")\n",
    "except StopIteration:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not support indexing ( it is a generator.. )\n",
    "try:\n",
    "    label_generator[0]\n",
    "    print(\"Can index\")\n",
    "except TypeError:\n",
    "    print(\"Unable to index\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_references(label):\n",
    "    print('\\n---  schema ids ---\\n')\n",
    "    show_schema_ids(label)\n",
    "    print(\"\\n--- mask urls ---\\n\")\n",
    "    print_mask_urls(label)\n",
    "    print('\\n--- image url ---\\n')\n",
    "    print(label.data.url)    \n",
    "    print('\\n--- data row reference ---\\n')\n",
    "    print(original_label.data.uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets add some functions to modify the result of the generator\n",
    "# Recreate because we already went through all of the items when we showed that it isn't repeatable\n",
    "original_label = labels[0]\n",
    "\n",
    "show_references(original_label)\n",
    "label_generator = LabelGenerator(labels) \\\n",
    "        .add_url_to_masks(signing_function) \\\n",
    "        .add_to_dataset(dataset, signing_function) \\\n",
    "        .assign_schema_ids(ontology)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is lazily evaluated.\n",
    "# So even after defining the functions the ids aren't set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_references(original_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = next(label_generator)\n",
    "show_references(original_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-chile",
   "metadata": {},
   "source": [
    "* Note that the first qsize elements run serially from when the chained functions are added.\n",
    "* After that iterating will get much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators can be converted to Collections\n",
    "LabelGenerator(labels).as_collection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.delete()\n",
    "project.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-stationery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-luxury",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
