{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stupid-court",
   "metadata": {},
   "source": [
    "# MAL With Annotation Types\n",
    "* Image MAL with subclasses.\n",
    "* This is the same task as the image mal tutorial but we are going to add a subclass for whether or not the person in the image is holding a bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import labelbox\n",
    "except: \n",
    "    !git clone https://github.com/Labelbox/labelbox-python.git\n",
    "    !cd labelbox-python && git checkout ms/annotation-examples && pip install .[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "honey-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these if running in a colab notebook\n",
    "COLAB = \"google.colab\" in str(get_ipython())\n",
    "if COLAB:\n",
    "    !git clone https://github.com/Labelbox/labelbox-python.git\n",
    "    !mv labelbox-python/examples/model_assisted_labeling/image_model.py .\n",
    "else:\n",
    "    import sys\n",
    "    sys.path.append('../model_assisted_labeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "committed-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used this as a reference for the model\n",
    "#https://colab.research.google.com/github/tensorflow/tpu/blob/master/models/official/mask_rcnn/mask_rcnn_demo.ipynb#scrollTo=6lCL-ZcwaJbA\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
    "from labelbox import Client, LabelingFrontend\n",
    "from labelbox.data.annotation_types import (\n",
    "    LabelList,\n",
    "    RasterData,\n",
    "    Rectangle,\n",
    "    ObjectAnnotation,\n",
    "    ClassificationAnnotation,\n",
    "    Point,\n",
    "    ClassificationAnswer,\n",
    "    Radio,\n",
    "    Mask,\n",
    "    Label\n",
    ")\n",
    "from labelbox.data.serialization import NDJsonConverter\n",
    "from image_model import predict, class_mappings, load_model\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "import ndjson\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "import os\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hydraulic-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't want to give google access to drive you can skip this cell\n",
    "# and manually set `API_KEY` below.\n",
    "if COLAB:\n",
    "    !pip install colab-env -qU\n",
    "    from colab_env import envvar_handler\n",
    "    envvar_handler.envload()\n",
    "\n",
    "API_KEY = os.environ.get(\"LABELBOX_API_KEY\")\n",
    "if not os.environ.get(\"LABELBOX_API_KEY\"):\n",
    "    API_KEY = getpass(\"Please enter your labelbox api key\")\n",
    "    if COLAB:\n",
    "        envvar_handler.add_env(\"LABELBOX_API_KEY\", API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exclusive-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this if running in colab. Otherwise it should work if you have the LABELBOX_API_KEY set.\n",
    "API_KEY = os.environ[\"LABELBOX_API_KEY\"]\n",
    "# Only update this if you have an on-prem deployment\n",
    "ENDPOINT = \"https://api.labelbox.com/graphql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polyphonic-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(api_key=API_KEY, endpoint=ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emotional-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../model_assisted_labeling/image_model.py:17: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from gs://cloud-tpu-checkpoints/mask-rcnn/1555659850/variables/variables\n"
     ]
    }
   ],
   "source": [
    "#Downloads weights and loads the model.\n",
    "load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-soundtrack",
   "metadata": {},
   "source": [
    "## Local first\n",
    "* No keys, no references. Just get started making inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interested-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_bag(person, bags):\n",
    "    for bag in bags:\n",
    "        if person.value.shapely.contains(bag.value.shapely.centroid):\n",
    "            return True\n",
    "    return False    \n",
    "\n",
    "def get_annotations(boxes, classes, seg_masks):\n",
    "    annotations = []\n",
    "        for box, class_idx, seg in zip(boxes, classes, seg_masks):\n",
    "        name = class_mappings[class_idx]\n",
    "        value = None\n",
    "        classifications = []\n",
    "        if name in ['person', 'handbag']:\n",
    "            value = Rectangle(\n",
    "                start = Point(x = box[1], y = box[0]), end = Point(x = box[3], y = box[2])\n",
    "            )\n",
    "        elif name == 'car':\n",
    "            value = Mask(mask = RasterData.from_2D_arr(arr = seg), color = (1,1,1))\n",
    "        if value is not None:\n",
    "            annotations.append(\n",
    "                ObjectAnnotation(\n",
    "                    name = name,\n",
    "                    value = value\n",
    "                )\n",
    "            ) \n",
    "    return annotations\n",
    "\n",
    "def update_bag_classifications(annotations):\n",
    "    bags = [annot for annot in annotations if annot.name == 'handbag']\n",
    "    people = [annot for annot in annotations if annot.name == 'person']\n",
    "    for person in people:\n",
    "        person.classifications = [ClassificationAnnotation(\n",
    "            name = 'has_bag',\n",
    "            value = Radio(answer = ClassificationAnswer(name = str(has_bag(person, bags))))\n",
    "        )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interstate-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can just start creating predictions whether or not we have a \n",
    "image_paths = ['/Users/matthewsokoloff/Downloads/kitano_st.jpeg']\n",
    "\n",
    "labellist = LabelList([])\n",
    "\n",
    "for image_url in image_paths:\n",
    "    image_data = RasterData(file_path = image_url)\n",
    "    height, width = image_data.data.shape[:2]\n",
    "    prediction = predict(np.array([image_data.im_bytes]), min_score=0.5, height=height, width = width)\n",
    "    annotations = get_annotations(prediction['boxes'], prediction['class_indices'], prediction['seg_masks'])\n",
    "    update_bag_classifications(annotations)\n",
    "    labellist.append(Label(\n",
    "        data = image_data,\n",
    "        annotations = annotations\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accessible-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this time it is a bit verbose.\n",
    "# We will be adding helper functions to make this easier.\n",
    "# Ie. geometry.from_prediction which will automatically figure out what you have..\n",
    "# Or even just like bbox.from_points\n",
    "# idk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-venture",
   "metadata": {},
   "source": [
    "### Project Setup\n",
    "* Same as before. Except we can add the data and ontology directly from the labellist\n",
    "* See `labellist.get_ontology()` and then the adding id section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "modern-program",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets setup a project to label\n",
    "# Note see Ontology, Project, and Project_setup notebooks for more information on this section.\n",
    "project = client.create_project(name=\"subclass_mal_project\")\n",
    "dataset = client.create_dataset(name=\"subclass_mal_dataset\")\n",
    "editor = next(\n",
    "    client.get_labeling_frontends(where=LabelingFrontend.name == 'editor'))\n",
    "# Use the label collection to build the ontology\n",
    "project.setup(editor, labellist.get_ontology().asdict())\n",
    "project.datasets.connect(dataset)\n",
    "project.enable_model_assisted_labeling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-functionality",
   "metadata": {},
   "source": [
    "### Add ids required for MAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vietnamese-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.40s/it]\n",
      "1it [00:05,  5.17s/it]\n",
      "1it [00:00, 9686.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<labelbox.data.annotation_types.collection.LabelList at 0x181106940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signer = lambda _bytes: client.upload_data(content=_bytes, sign=True)\n",
    "labellist.add_url_to_masks(signer) \\\n",
    "         .add_url_to_data(signer) \\\n",
    "         .assign_schema_ids(OntologyBuilder.from_project(project)) \\\n",
    "         .add_to_dataset(dataset, signer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-grenada",
   "metadata": {},
   "source": [
    "### Convert to Prediction import format (NDJson)\n",
    "* We want to create a json payload that matches this: https://docs.labelbox.com/data-model/en/index-en#annotations\n",
    "* Here we will run inferences on all of our data (only one image this time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "multiple-values",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uuid': '2be62464-6f40-4022-800a-60e28ed21ad6', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'schemaId': 'ckrjmvkw9lned0y8u0uz6cpmd', 'classifications': [{'schemaId': 'ckrjmvkwwlnej0y8uaxy0btap', 'answer': {'schemaId': 'ckrjmvkxdlnel0y8ugxoh9qw9'}}], 'bbox': {'top': 2166.56884765625, 'left': 3658.38427734375, 'height': 562.581787109375, 'width': 207.585205078125}}\n"
     ]
    }
   ],
   "source": [
    "ndjsons = list(NDJsonConverter.serialize(labellist))\n",
    "print(ndjsons[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-library",
   "metadata": {},
   "source": [
    "### Upload the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deluxe-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_task = project.upload_annotations(name=f\"upload-job-{uuid.uuid4()}\",\n",
    "                                         annotations=ndjsons,\n",
    "                                         validate=True)\n",
    "# Wait for upload to finish\n",
    "upload_task.wait_until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "clean-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uuid': '2be62464-6f40-4022-800a-60e28ed21ad6', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '4272fb66-8b8f-4d38-99f7-1fda2ff7fb3d', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '2ff416c4-8cf7-4f07-81c9-009ae2b550b7', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '9709fb30-dc6a-4c8f-a2ca-b2741bd4f676', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'ed8b7e18-8f9e-4f3b-b24f-a0d274a52f8c', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '4735ddad-6b2d-4652-9c8d-fa07b63a7b1e', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '3fc59e3f-2388-41ca-9999-583efa6830f6', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '7bfc2697-7467-40b9-8d6f-3fc9e097c51a', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'c08fbe2e-39b8-420b-992f-1a610f045cb7', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'a0fb71e5-b18b-4b06-b7a7-8ed7c619e703', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '023af2e2-68c0-43a1-90d4-7012e2508c82', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'be34ee1c-a169-48c3-a4c3-0863691f1584', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'e15d6ebf-a4d9-49ac-b7d1-10a941a645d1', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '8511df06-1cc2-43b2-a69e-5cfd7dca6033', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'f204fc99-9a0a-49d6-aa5f-11e00abfe704', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '824066ca-0e68-4186-a916-4c5f5c071332', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '99533fe6-681a-464a-9ad7-bc25f89befc1', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'a413c6f8-998a-4b3e-a8b5-9d06a0913569', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'e158be0d-7fbb-4e14-8c4b-5fd071a33eaa', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '2338995b-8b5c-43af-a75e-c787e1e4f73d', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '0b70770c-bdd7-4f6a-bffe-61310371be27', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '2d6e3249-e043-40f6-97e9-262fe1a9082f', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'd3656e82-f9fb-49c8-a56a-d6bf51b0f71b', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '806bae16-0648-4b93-ab83-068af69c9a74', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '2816209a-996b-4704-818b-d7cfe1211850', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'd9bb16b0-de74-436f-ac53-6b8ed15c5f5b', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '8f70d77f-f2d4-484e-b738-8cb13449a40d', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '6fec9bf6-7089-4501-bfa9-f2029582199b', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '703afe24-f572-433b-b5dc-111aa542d2c8', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '7ca9246d-fafc-4e79-bd32-5bf4ab9543ca', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '469b2862-8c37-4193-b26d-91690c25ea39', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '25dc8c66-d16a-4342-9d37-5074765e7568', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'b38ed92d-fbb5-4736-ac74-1d7cec8933d7', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '80a9c267-f80d-4e95-8266-ce3b4c60705c', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '35a936b9-10d5-4469-950d-23b7b5367832', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '2cdd7748-3665-49a8-a1fc-c0a9f7a9c570', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '95e5f042-03fb-4cff-9101-b4f1df9babaf', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'b04ac505-cd6c-40bb-a14d-5dde52594333', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '78a9afbf-9d0e-4167-97bc-58523e71ff19', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '68df1947-3ae1-4ad8-aaba-418453c7d730', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '272bcbac-d03a-438f-80ed-fbe24399bd8f', 'dataRow': {'id': 'ckrjmvvkcu9hb0ypk3o255gm8'}, 'status': 'SUCCESS'}\n"
     ]
    }
   ],
   "source": [
    "# Review the upload status\n",
    "for status in upload_task.statuses:\n",
    "    print(status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
