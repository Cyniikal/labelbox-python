{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stupid-court",
   "metadata": {},
   "source": [
    "# MAL With Annotation Types\n",
    "* Image MAL with subclasses.\n",
    "* This is the same task as the image mal tutorial but we are going to add a subclass for whether or not the person in the image is holding a bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "danish-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import labelbox\n",
    "except: \n",
    "    !git clone https://github.com/Labelbox/labelbox-python.git\n",
    "    !cd labelbox-python && git checkout ms/annotation-examples && pip install .[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "honey-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these if running in a colab notebook\n",
    "COLAB = \"google.colab\" in str(get_ipython())\n",
    "if COLAB:\n",
    "    !git clone https://github.com/Labelbox/labelbox-python.git\n",
    "    !mv labelbox-python/examples/model_assisted_labeling/image_model.py .\n",
    "else:\n",
    "    import sys\n",
    "    sys.path.append('../model_assisted_labeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "committed-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used this as a reference for the model\n",
    "#https://colab.research.google.com/github/tensorflow/tpu/blob/master/models/official/mask_rcnn/mask_rcnn_demo.ipynb#scrollTo=6lCL-ZcwaJbA\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
    "from labelbox import Client, LabelingFrontend\n",
    "from labelbox.data.annotation_types import (\n",
    "    LabelList,\n",
    "    RasterData,\n",
    "    Rectangle,\n",
    "    ObjectAnnotation,\n",
    "    ClassificationAnnotation,\n",
    "    Point,\n",
    "    ClassificationAnswer,\n",
    "    Radio,\n",
    "    Mask,\n",
    "    Label\n",
    ")\n",
    "from labelbox.data.serialization import NDJsonConverter\n",
    "from image_model import predict, class_mappings, load_model\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "import ndjson\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "import os\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hydraulic-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't want to give google access to drive you can skip this cell\n",
    "# and manually set `API_KEY` below.\n",
    "if COLAB:\n",
    "    !pip install colab-env -qU\n",
    "    from colab_env import envvar_handler\n",
    "    envvar_handler.envload()\n",
    "\n",
    "API_KEY = os.environ.get(\"LABELBOX_API_KEY\")\n",
    "if not os.environ.get(\"LABELBOX_API_KEY\"):\n",
    "    API_KEY = getpass(\"Please enter your labelbox api key\")\n",
    "    if COLAB:\n",
    "        envvar_handler.add_env(\"LABELBOX_API_KEY\", API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exclusive-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this if running in colab. Otherwise it should work if you have the LABELBOX_API_KEY set.\n",
    "API_KEY = os.environ[\"LABELBOX_API_KEY\"]\n",
    "# Only update this if you have an on-prem deployment\n",
    "ENDPOINT = \"https://api.labelbox.com/graphql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polyphonic-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(api_key=API_KEY, endpoint=ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emotional-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../model_assisted_labeling/image_model.py:17: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from gs://cloud-tpu-checkpoints/mask-rcnn/1555659850/variables/variables\n"
     ]
    }
   ],
   "source": [
    "#Downloads weights and loads the model.\n",
    "load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-soundtrack",
   "metadata": {},
   "source": [
    "## Create Predictions\n",
    "* Create helper functions for processing the model outputs\n",
    "* Make predictions\n",
    "* Add predictions to a LabelList object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interested-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_bag(person, bags):\n",
    "    for bag in bags:\n",
    "        if person.value.shapely.contains(bag.value.shapely.centroid):\n",
    "            return True\n",
    "    return False    \n",
    "\n",
    "def get_annotations(boxes, classes, seg_masks):\n",
    "    annotations = []\n",
    "    for box, class_idx, seg in zip(boxes, classes, seg_masks):\n",
    "        name = class_mappings[class_idx]\n",
    "        value = None\n",
    "        classifications = []\n",
    "        if name in ['person', 'handbag']:\n",
    "            value = Rectangle(\n",
    "                start = Point(x = box[1], y = box[0]), end = Point(x = box[3], y = box[2])\n",
    "            )\n",
    "        elif name == 'car':\n",
    "            value = Mask(mask = RasterData.from_2D_arr(arr = seg), color = (1,1,1))\n",
    "        if value is not None:\n",
    "            annotations.append(\n",
    "                ObjectAnnotation(\n",
    "                    name = name,\n",
    "                    value = value\n",
    "                )\n",
    "            ) \n",
    "    return annotations\n",
    "\n",
    "def update_bag_classifications(annotations):\n",
    "    bags = [annot for annot in annotations if annot.name == 'handbag']\n",
    "    people = [annot for annot in annotations if annot.name == 'person']\n",
    "    for person in people:\n",
    "        person.classifications = [ClassificationAnnotation(\n",
    "            name = 'has_bag',\n",
    "            value = Radio(answer = ClassificationAnswer(name = str(has_bag(person, bags))))\n",
    "        )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interstate-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can just start creating predictions whether or not we have a \n",
    "image_urls = ['https://raw.githubusercontent.com/Labelbox/labelbox-python/develop/examples/assets/2560px-Kitano_Street_Kobe01s5s4110.jpg']\n",
    "\n",
    "labellist = LabelList([])\n",
    "\n",
    "for image_url in image_urls:\n",
    "    image_data = RasterData(url = image_url)\n",
    "    height, width = image_data.data.shape[:2]\n",
    "    prediction = predict(np.array([image_data.im_bytes]), min_score=0.5, height=height, width = width)\n",
    "    annotations = get_annotations(prediction['boxes'], prediction['class_indices'], prediction['seg_masks'])\n",
    "    update_bag_classifications(annotations)\n",
    "    labellist.append(Label(\n",
    "        data = image_data,\n",
    "        annotations = annotations\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-venture",
   "metadata": {},
   "source": [
    "## Project Setup\n",
    "* Create project\n",
    "* Use labellist.get_ontology() to automatically create the OntologyBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "modern-program",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets setup a project to label\n",
    "# Note see Ontology, Project, and Project_setup notebooks for more information on this section.\n",
    "project = client.create_project(name=\"mal_project\")\n",
    "dataset = client.create_dataset(name=\"mal_dataset\")\n",
    "editor = next(\n",
    "    client.get_labeling_frontends(where=LabelingFrontend.name == 'editor'))\n",
    "# Use the label collection to build the ontology\n",
    "project.setup(editor, labellist.get_ontology().asdict())\n",
    "project.datasets.connect(dataset)\n",
    "project.enable_model_assisted_labeling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-functionality",
   "metadata": {},
   "source": [
    "## Add ids required for MAL\n",
    "* Use helper functions to add urls to images and seg masks, assign schema ids to features, and add all data rows to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vietnamese-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.18s/it]\n",
      "1it [00:00, 4549.14it/s]\n",
      "1it [00:00, 13148.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<labelbox.data.annotation_types.collection.LabelList at 0x1828c8490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signer = lambda _bytes: client.upload_data(content=_bytes, sign=True)\n",
    "labellist.add_url_to_masks(signer) \\\n",
    "         .add_url_to_data(signer) \\\n",
    "         .assign_schema_ids(OntologyBuilder.from_project(project)) \\\n",
    "         .add_to_dataset(dataset, signer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-grenada",
   "metadata": {},
   "source": [
    "## Convert to Prediction import format (NDJson)\n",
    "* We want to create a json payload that matches this: https://docs.labelbox.com/data-model/en/index-en#annotations\n",
    "* We can use the NDJsonConverter to turn our labellist containg predictions into ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "multiple-values",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uuid': '12947ab8-616f-4493-a310-d04e95adabca', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'schemaId': 'ckrmsae6301e00y8dejvfc7ar', 'classifications': [{'schemaId': 'ckrmsae6o01e60y8d7o0e3j9x', 'answer': {'schemaId': 'ckrmsae7801e80y8ddmar36r7'}}], 'bbox': {'top': 1352.3682861328125, 'left': 2275.82861328125, 'height': 350.1317138671875, 'width': 139.7919921875}}\n"
     ]
    }
   ],
   "source": [
    "ndjsons = list(NDJsonConverter.serialize(labellist))\n",
    "print(ndjsons[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-library",
   "metadata": {},
   "source": [
    "### Upload the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deluxe-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_task = project.upload_annotations(name=f\"upload-job-{uuid.uuid4()}\",\n",
    "                                         annotations=ndjsons,\n",
    "                                         validate=True)\n",
    "# Wait for upload to finish\n",
    "upload_task.wait_until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "clean-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uuid': '12947ab8-616f-4493-a310-d04e95adabca', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '864a560f-0b53-446b-83cd-c9fff1586495', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'e08f528f-3cf6-4bd8-8468-09b18c3380fb', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '96c30b98-323e-4aee-8cfa-626c727d1b19', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'ef570524-80de-4765-972f-f7caf8b866d1', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '2c9aa3a0-26a6-474e-99d6-60cd23a86b77', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'f860861f-2cb4-48dc-9314-1871138a44f0', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '5a584ef4-8005-479e-8677-def103944ebe', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '8901ecd8-ee62-4fb1-8b83-e63e01ce3b09', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'd8c195c3-3565-42eb-837f-29f8cda553d4', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'ee72d3cb-1042-4223-91c9-dfc1022a895e', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '873e5395-d09c-4dce-85ed-41df0f1297e6', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '7a0c4915-15c5-420e-8ec0-8e9b2a466b3e', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'd3913509-a830-4d42-b462-197accd8d065', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '6756464d-36d8-44eb-8602-60790c3d1665', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'c9daf184-c47c-4cd9-a8ce-88a39297eda2', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '74e42085-399d-4e09-9eb1-9181ab103c3a', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '98610111-12e8-402c-a0e5-cdba04799729', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'e3616e11-0406-4db6-ac24-ccef5410f2b3', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'e87daf42-43ce-4160-b53c-9b2913dab589', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '05657766-fee2-4d5f-a91b-9059565fd999', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'd09525b0-206f-4cb2-8487-1bfd6e6ba1b4', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '9660b24e-855f-4577-8910-4044b2db795a', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '4193869e-d058-4202-8e44-6fdce97b0d1c', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '8030a4a2-4fe3-4e70-954f-2945a8472a38', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '472aaf0c-fc94-4ac7-ba4c-9b8ddb2dcb63', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '032fe1ca-d2cb-4932-b993-9d477cbd3af5', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '614a912a-d939-4ee0-ae32-de31e8cfe2c6', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'fddda853-493f-4906-9e51-e3f240dabb89', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'd9ddc148-dc7a-41ff-9226-2785dd2f5100', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '37efd7e8-b71f-4bef-8be1-e9087c5161ef', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': 'b3e4de27-26a0-4dec-a48b-6ede083897c6', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '7ed90447-c511-40cd-a6af-de437a800217', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '3d71b946-74b7-4672-be5b-3e25d87d81c1', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '54fd05a4-3d7f-4798-b037-8a6e02232cc7', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n",
      "{'uuid': '6c0068be-2004-4943-9e42-7199ff35df53', 'dataRow': {'id': 'ckrmse31q7vvy0yu0bac35o1z'}, 'status': 'SUCCESS'}\n"
     ]
    }
   ],
   "source": [
    "# Review the upload status\n",
    "for status in upload_task.statuses:\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-salem",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
