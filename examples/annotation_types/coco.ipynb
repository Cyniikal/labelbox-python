{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "standard-mercy",
   "metadata": {},
   "source": [
    "# COCO\n",
    "* The Coco format is compatible with a wide range of tools...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on:\n",
    "# https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=Ya5nEuMELeq8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "!pip3 install tensorboard\n",
    "# If running on osx\n",
    "!export ARCHFLAGS=\"-arch x86_64\" && CC=clang CXX=clang++ pip3 install pycocotools\n",
    "#!pip3 install pycocotools\n",
    "!export ARCHFLAGS=\"-arch x86_64\" && CC=clang CXX=clang++ pip3 install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-founder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "systematic-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelbox import Client\n",
    "import os\n",
    "from labelbox.data.serialization.coco.instance_dataset import CocoInstanceDataset \n",
    "from labelbox.data.serialization.coco.panoptic_dataset import CocoPanopticDataset\n",
    "from labelbox.data.annotation_types import Mask\n",
    "from detectron2.data.datasets import register_coco_instances,register_coco_panoptic\n",
    "import cv2\n",
    "import random\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from PIL import Image\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pacific-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = Client(api_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3JnZnRtMDIwMDAzMHliOTBkcTBmZmxsIiwib3JnYW5pemF0aW9uSWQiOiJjazZzbWptY3MwMXpkMDg5MXlna2V4OHMyIiwiYXBpS2V5SWQiOiJja3MzY3d2ejMwMDBrMHo2aTYxMjk2aGxvIiwic2VjcmV0IjoiZWMyNjgyYzVmZGYwYTIyZGZkYjdlOTM0MjQyMzVlNjkiLCJpYXQiOjE2Mjg0MzYyNzUsImV4cCI6MjI1OTU4ODI3NX0.b9MYfpZ4ueAqXtsl_4UpdvxKfCBfxvHGomoqSzPHuOc\", \n",
    "#                endpoint = \"https://staging-api.labelbox.com/graphql\")\n",
    "\n",
    "client = Client(api_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3FjeDFkMDMwNjg0MHk2MWJvd2I1anI1Iiwib3JnYW5pemF0aW9uSWQiOiJja3FjeDFjem4wNjgzMHk2MWdoOXYwMmNzIiwiYXBpS2V5SWQiOiJja3MzZDk1dXU3ZWlhMHllajZlcnA4dzAxIiwic2VjcmV0IjoiOWYwZjFlN2ZlMTZmNmY3MzBhNzE2MGYyNGFhNzc3MmMiLCJpYXQiOjE2Mjg0MzY4NDgsImV4cCI6MjI1OTU4ODg0OH0.csA2kQN-_u_qO1n1q5prxzFut2sGHuiw-eitSSohQoY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "facial-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"ckqcx1d58068d0y61c8175i69\" #\"ckputryh2000h0y8b65dfbo9r\" #\"ckq4q69ru004f0yah8sj289v2\"\n",
    "image_root = \"/tmp/images/\"\n",
    "mask_root = \"/tmp/masks/\"\n",
    "proj = client.get_project(project_id)\n",
    "labels = proj.label_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-clearance",
   "metadata": {},
   "source": [
    "* Set up directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decreased-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:14,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(im_root):\n",
    "    os.mkdir(im_root)\n",
    "\n",
    "if not os.path.exists(mask_root):\n",
    "    os.mkdir(mask_root)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = CocoInstanceDataset.from_common(\n",
    "    labels = labels, \n",
    "    image_root = im_root\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = coco.dict()\n",
    "images = coco['images']\n",
    "n_classes = len({category['id'] for category in coco['categories']})\n",
    "random.shuffle(images)\n",
    "\n",
    "def get_annotations(images, all_annotations):\n",
    "    image_lookup = {image['id'] for image in images}\n",
    "    return [annot for annot in all_annotations if annot['image_id'] in image_lookup]\n",
    "\n",
    "\n",
    "train_partition = dict(\n",
    "    categories = coco['categories'],\n",
    "    images = images[:int(0.8 * len(images))],\n",
    "    annotations = get_annotations(images[:int(0.8 * len(images))], coco['annotations'])\n",
    ")\n",
    "                         \n",
    "                              \n",
    "test_partition = dict(\n",
    "    categories = coco['categories'],\n",
    "    images = images[int(0.8 * len(images)):],\n",
    "    annotations = get_annotations(images[int(0.8 * len(images)):], coco['annotations']) \n",
    ")\n",
    "\n",
    "\n",
    "train_ds_path, test_ds_path = '/tmp/json_train_annotations.json', '/tmp/json_test_annotations.json'\n",
    "with open(train_ds_path, 'w') as file:\n",
    "    json.dump(train_partition, file)\n",
    "\n",
    "with open(test_ds_path, 'w') as file:\n",
    "    json.dump(test_partition, file)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"custom_coco_train\", {}, train_ds_path, im_root)\n",
    "register_coco_instances(\"custom_coco_test\", {}, test_ds_path, im_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets.coco import load_coco_json\n",
    "MetadataCatalog.get(\"custom_coco_test\").thing_classes = {r['id'] : r['name'] for r in coco['categories']}\n",
    "test_json = load_coco_json('/tmp/json_test_annotations.json', im_root)\n",
    "images = []\n",
    "import numpy as np\n",
    "for idx, example in enumerate(test_json):\n",
    "    if idx > 5:\n",
    "        break\n",
    "    \n",
    "    im = cv2.imread(example['file_name'])\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(\"custom_coco_test\"), scale=1.0)\n",
    "    out = v.draw_dataset_dict(example)\n",
    "    images.append(out.get_image())\n",
    "Image.fromarray(np.vstack(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"custom_coco_train\",)\n",
    "\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.MODEL.DEVICE = 'cpu'\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025 \n",
    "cfg.SOLVER.MAX_ITER = 20\n",
    "cfg.SOLVER.STEPS = []        \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = n_classes \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "\"\"\"\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluator = COCOEvaluator(\"custom_coco_test\")\n",
    "val_loader = build_detection_test_loader(cfg, \"custom_coco_test\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-terry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use `Visualizer` to draw the predictions on the image.\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "import numpy as np\n",
    "for idx, batch in enumerate(iter(val_loader)):\n",
    "    if idx > 3:\n",
    "        break\n",
    "    batch_inferences = []\n",
    "    for example in batch:\n",
    "        im = np.transpose(example['image'].numpy(), [1,2,0])\n",
    "        outputs = predictor(im)\n",
    "        v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        batch_inferences.append(out.get_image()[:, :, ::-1])\n",
    "    images.append(np.hstack(batch_inferences))\n",
    "Image.fromarray(np.vstack(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(\"custom_coco_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(\"custom_coco_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-barrier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-return",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-invite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-chapter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-bedroom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-james",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panoptic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"ckputryh2000h0y8b65dfbo9r\" #\"ckq4q69ru004f0yah8sj289v2\"\n",
    "proj = client.get_project(project_id)\n",
    "labels = proj.label_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make sure data exists...\n",
    "im_root = \"/tmp/images\"\n",
    "mask_root = \"/tmp/masks\"\n",
    "if not os.path.exists(im_root):\n",
    "    os.mkdir(im_root)\n",
    "\n",
    "if not os.path.exists(mask_root):\n",
    "    os.mkdir(mask_root)\n",
    "    \n",
    "    \n",
    "lbls = []\n",
    "for idx, label in enumerate(labels):\n",
    "    lbls.append(label)\n",
    "    if idx > 10:\n",
    "        break\n",
    "        \n",
    "coco = CocoPanopticDataset.from_common(\n",
    "    labels = lbls, \n",
    "    image_root = im_root,\n",
    "    seg_root = mask_root\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_instance = CocoInstanceDataset.from_common(\n",
    "    labels = lbls, \n",
    "    image_root = im_root\n",
    ").dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = coco.dict() # Remove this once we refresh the notebook\n",
    "n_classes = len({category['id'] for category in coco['categories']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = coco['images']\n",
    "import random\n",
    "random.shuffle(images)\n",
    "\n",
    "def get_annotations(images, all_annotations):\n",
    "    image_lookup = {image['id'] for image in images}\n",
    "    return [annot for annot in all_annotations if annot['image_id'] in image_lookup]\n",
    "\n",
    "\n",
    "train_partition = dict(\n",
    "    categories = coco['categories'],\n",
    "    images = images[:int(0.8 * len(images))],\n",
    "    annotations = get_annotations(images[:int(0.8 * len(images))], coco['annotations'])\n",
    ")\n",
    "\n",
    "train_instance_parition = dict(\n",
    "    categories = coco_instance['categories'],\n",
    "    images = images[:int(0.8 * len(images))],\n",
    "    annotations = get_annotations(images[:int(0.8 * len(images))], coco_instance['annotations'])\n",
    ")\n",
    "                         \n",
    "\n",
    "                              \n",
    "test_partition = dict(\n",
    "    categories = coco['categories'],\n",
    "    images = images[int(0.8 * len(images)):],\n",
    "    annotations = get_annotations(images[int(0.8 * len(images)):], coco['annotations']) \n",
    ")\n",
    "\n",
    "train_ds_path, test_ds_path, train_ds_instance_path = '/tmp/json_train_annotations.json', '/tmp/json_test_annotations.json', '/tmp/instances.json'\n",
    "with open(train_ds_path, 'w') as file:\n",
    "    json.dump(train_partition, file)\n",
    "\n",
    "with open(test_ds_path, 'w') as file:\n",
    "    json.dump(test_partition, file)    \n",
    "    \n",
    "with open(train_ds_instance_path, 'w') as file:\n",
    "    json.dump(train_instance_parition, file)    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "{r['id'] : r['name'] for r in coco['categories']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_classes = ['car']\n",
    "thing_classes = ['person']\n",
    "stuff_dataset_id_to_contiguous_id = {0:0}\n",
    "thing_dataset_id_to_contiguous_id = {0:0}\n",
    "mmeta = {\n",
    "    'stuff_classes' : stuff_classes,\n",
    "    'thing_classes' : thing_classes,\n",
    "    'stuff_dataset_id_to_contiguous_id' : stuff_dataset_id_to_contiguous_id,\n",
    "    'thing_dataset_id_to_contiguous_id' : thing_dataset_id_to_contiguous_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mmeta = {'thing_dataset_id_to_contiguous_id' : {idx:0}}\n",
    "#indices = range(len({r['id'] : r['name'] for r in coco['categories']}))\n",
    "#mmeta.update({'stuff_dataset_id_to_contiguous_id' : {idx:idx for idx in indices if idx != 0}})\n",
    "#mmeta.update({'thing_classes' : list({r['name'] for r in coco['categories']})})\n",
    "#mmeta.update({'stuff_classes' : list({r['name'] for r in coco['categories']})})\n",
    "\n",
    "\n",
    "#register_coco_panoptic(\"panoptic_train_6\", mmeta,im_root,  mask_root,train_ds_path)\n",
    "#register_coco_panoptic(\"panoptic_test_6\", mmeta, im_root, mask_root,test_ds_path)\n",
    "\n",
    "# We need thing and stuff classes and we need to set the mapping.\n",
    "\n",
    "\n",
    "\n",
    "from detectron2.data.datasets import register_coco_panoptic_separated\n",
    "#register_coco_panoptic_separated(name, metadata, \n",
    "#        image_root, panoptic_root, panoptic_json, sem_seg_root, instances_json).\n",
    "#My_code\n",
    "\n",
    "register_coco_panoptic_separated(\"panoptic_train_7\", mmeta, \n",
    "        im_root, \n",
    "        mask_root, train_ds_path, \n",
    "        mask_root, train_ds_instance_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets.coco import load_coco_json\n",
    "from detectron2.data.datasets.coco_panoptic import load_coco_panoptic_json\n",
    "print(MetadataCatalog.get(\"panoptic_train_7_separated\"))\n",
    "test_json = load_coco_panoptic_json(test_ds_path, im_root, mask_root ,{})\n",
    "images = []\n",
    "import numpy as np\n",
    "for idx, example in enumerate(test_json):\n",
    "    if idx > 5:\n",
    "        break\n",
    "    \n",
    "    im = cv2.imread(example['file_name'])\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(\"panoptic_train_7_separated\"), scale=1.0)\n",
    "    out = v.draw_dataset_dict(example)\n",
    "    images.append(out.get_image())\n",
    "Image.fromarray(np.vstack(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"panoptic_train_5_separated\",)\n",
    "\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.MODEL.DEVICE = 'cpu'\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025 \n",
    "cfg.SOLVER.MAX_ITER = 300\n",
    "cfg.SOLVER.STEPS = []        \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = n_classes \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "trainer = DefaultTrainer(cfg) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/cocodataset/panopticapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from fvcore.common.download import download\n",
    "from panopticapi.utils import rgb2id\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _process_panoptic_to_semantic(input_panoptic, output_semantic, segments, id_map):\n",
    "    panoptic = np.asarray(Image.open(input_panoptic), dtype=np.uint32)\n",
    "    panoptic = rgb2id(panoptic)\n",
    "    output = np.zeros_like(panoptic, dtype=np.uint8) + 255\n",
    "    for seg in segments:\n",
    "        cat_id = seg[\"category_id\"]\n",
    "        new_cat_id = id_map[cat_id]\n",
    "        output[panoptic == seg[\"id\"]] = new_cat_id\n",
    "    Image.fromarray(output).save(output_semantic)\n",
    "\n",
    "\n",
    "def separate_coco_semantic_from_panoptic(panoptic_json, panoptic_root, sem_seg_root, categories):\n",
    "    \"\"\"\n",
    "    Create semantic segmentation annotations from panoptic segmentation\n",
    "    annotations, to be used by PanopticFPN.\n",
    "    It maps all thing categories to class 0, and maps all unlabeled pixels to class 255.\n",
    "    It maps all stuff categories to contiguous ids starting from 1.\n",
    "    Args:\n",
    "        panoptic_json (str): path to the panoptic json file, in COCO's format.\n",
    "        panoptic_root (str): a directory with panoptic annotation files, in COCO's format.\n",
    "        sem_seg_root (str): a directory to output semantic annotation files\n",
    "        categories (list[dict]): category metadata. Each dict needs to have:\n",
    "            \"id\": corresponds to the \"category_id\" in the json annotations\n",
    "            \"isthing\": 0 or 1\n",
    "    \"\"\"\n",
    "    os.makedirs(sem_seg_root, exist_ok=True)\n",
    "\n",
    "    stuff_ids = [k[\"id\"] for k in categories] # if k[\"isthing\"] == 0]\n",
    "    thing_ids = [] #[k[\"id\"] for k in categories if k[\"isthing\"] == 1]\n",
    "    id_map = {}  # map from category id to id in the output semantic annotation\n",
    "    assert len(stuff_ids) <= 254\n",
    "    for i, stuff_id in enumerate(stuff_ids):\n",
    "        id_map[stuff_id] = i + 1\n",
    "    for thing_id in thing_ids:\n",
    "        id_map[thing_id] = 0\n",
    "    id_map[0] = 255\n",
    "\n",
    "    with open(panoptic_json) as f:\n",
    "        obj = json.load(f)\n",
    "\n",
    "\n",
    "    def iter_annotations():\n",
    "        for anno in obj[\"annotations\"]:\n",
    "            file_name = anno[\"file_name\"]\n",
    "            segments = anno[\"segments_info\"]\n",
    "            input = os.path.join(panoptic_root, file_name)\n",
    "            output = os.path.join(sem_seg_root, file_name)\n",
    "            yield input, output, segments\n",
    "\n",
    "    print(\"Start writing to {} ...\".format(sem_seg_root))\n",
    "    start = time.time()\n",
    "    for i,o,s in iter_annotations():\n",
    "        _process_panoptic_to_semantic(i,o,s, id_map)\n",
    "    print(\"Finished. time: {:.2f}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_coco_semantic_from_panoptic(train_ds_path, mask_root, \"/tmp/segs\", coco['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "panoptic_json, panoptic_root, sem_seg_root, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /\"tmp/segs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-wealth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-habitat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-karaoke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-latino",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-upgrade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-gospel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-antenna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-basement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-moderator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-procurement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-replication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-somalia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_panoptic_separated(\"panoptic_train_5\", mmeta, \n",
    "        im_root, \n",
    "        mask_root, train_ds_path, \n",
    "        mask_root, train_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-hormone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'panoptic-training-11_separated'\n",
    "\n",
    "register_coco_panoptic_separated(\"panoptic-training-11\", {}, #mmeta, \n",
    "        im_root, \n",
    "        mask_root, train_ds_path, \n",
    "        \"/tmp/segs\", train_ds_instance_path)\n",
    "\n",
    "tings = ['person', 'car']\n",
    "stuffs = ['person', 'car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(\"panoptic-training-11_separated\").set(thing_classes=tings, stuff_classes=stuffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\"\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(config_file))\n",
    "cfg.DATASETS.TRAIN = (\"panoptic-training-11_separated\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.MODEL.DEVICE = 'cpu'\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_file)  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "# 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.SOLVER.MAX_ITER = 200\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(tings)\n",
    "cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = len(stuffs)\n",
    "cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "# for single test image\n",
    "im = np.array(Image.open('/tmp/images/5.jpg'))\n",
    "panoptic_seg, segments_info = predictor(im)[\"panoptic_seg\"]\n",
    "#v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get('new'), scale=1.2)\n",
    "v = v.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n",
    "# panoptic segmentation result\n",
    "Image.fromarray(v.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get('new').thing_classes = ['person', 'car', 'other']\n",
    "MetadataCatalog.get('new').stuff_classes = ['person', 'car', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(cfg.DATASETS.TRAIN[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray( panoptic_seg.numpy().astype(np.uint8)* 36) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-inspector",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
