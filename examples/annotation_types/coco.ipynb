{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "standard-mercy",
   "metadata": {},
   "source": [
    "# COCO\n",
    "* The Coco format is compatible with a wide range of tools...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on:\n",
    "# https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=Ya5nEuMELeq8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "!pip3 install tensorboard\n",
    "# If running on osx\n",
    "!export ARCHFLAGS=\"-arch x86_64\" && CC=clang CXX=clang++ pip3 install pycocotools\n",
    "#!pip3 install pycocotools\n",
    "!export ARCHFLAGS=\"-arch x86_64\" && CC=clang CXX=clang++ pip3 install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-founder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "systematic-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelbox import Client\n",
    "import os\n",
    "from labelbox.data.serialization.coco.instance_dataset import CocoInstanceDataset \n",
    "from labelbox.data.serialization.coco.panoptic_dataset import CocoPanopticDataset\n",
    "from labelbox.data.annotation_types import Mask\n",
    "from detectron2.data.datasets import register_coco_instances,register_coco_panoptic\n",
    "import cv2\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from PIL import Image\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pacific-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(api_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3JnZnRtMDIwMDAzMHliOTBkcTBmZmxsIiwib3JnYW5pemF0aW9uSWQiOiJjazZzbWptY3MwMXpkMDg5MXlna2V4OHMyIiwiYXBpS2V5SWQiOiJja3J0dDBvcmowM21hMHphaWQ2Ym1oOHhpIiwic2VjcmV0IjoiMzk0NTM2NDJmNDNmNTRmYzA1OTQwNmZkNWRhNGI1ODIiLCJpYXQiOjE2Mjc4NTg2NjUsImV4cCI6MjI1OTAxMDY2NX0.QSMv-Xkevw98EfBr3y1edgzHBp6GaCkrNV1JeTbA2fQ\", \n",
    "                endpoint = \"https://staging-api.labelbox.com/graphql\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "facial-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"ckputryh2000h0y8b65dfbo9r\" #\"ckq4q69ru004f0yah8sj289v2\"\n",
    "proj = client.get_project(project_id)\n",
    "labels = proj.label_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-handy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respected-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "drawn-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 5, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/enums.py\", line 104, in <module>\n",
      "    class Interleaving(Enum):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/enum.py\", line 161, in __new__\n",
      "    classdict['__doc__'] = 'An enumeration.'\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/enum.py\", line 90, in __setitem__\n",
      "    elif _is_dunder(key):\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 6, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/env.py\", line 3, in <module>\n",
      "    import attr\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/__init__.py\", line 7, in <module>\n",
      "    from . import converters, exceptions, filters, setters, validators\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/converters.py\", line 7, in <module>\n",
      "    from ._make import NOTHING, Factory, pipe\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/_make.py\", line 2476, in <module>\n",
      "    _add_eq(\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/_make.py\", line 1666, in _add_eq\n",
      "    cls.__eq__ = _make_eq(cls, attrs)\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/_make.py\", line 1594, in _make_eq\n",
      "    bytecode = compile(script, unique_filename, \"exec\")\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 5, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/enums.py\", line 28, in <module>\n",
      "    class Resampling(IntEnum):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/enum.py\", line 171, in __new__\n",
      "    dynamic_attributes = {k for c in enum_class.mro()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/enum.py\", line 172, in <setcomp>\n",
      "    for k, v in c.__dict__.items()\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 6, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/env.py\", line 3, in <module>\n",
      "    import attr\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/__init__.py\", line 7, in <module>\n",
      "    from . import converters, exceptions, filters, setters, validators\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/validators.py\", line 344, in <module>\n",
      "    class _DeepMapping(object):\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/_make.py\", line 1359, in wrap\n",
      "    builder.add_hash()\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/_make.py\", line 841, in add_hash\n",
      "    _make_hash(\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/_make.py\", line 1466, in _make_hash\n",
      "    unique_filename = _generate_unique_filename(cls, \"hash\")\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/attr/_make.py\", line 1433, in _generate_unique_filename\n",
      "    unique_id = uuid.uuid4()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/uuid.py\", line 780, in uuid4\n",
      "    return UUID(bytes=os.urandom(16), version=4)\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 6, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/env.py\", line 17, in <module>\n",
      "    from rasterio.session import Session, DummySession\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/session.py\", line 12, in <module>\n",
      "    import boto3\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/__init__.py\", line 16, in <module>\n",
      "    from boto3.session import Session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/session.py\", line 17, in <module>\n",
      "    import botocore.session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/session.py\", line 29, in <module>\n",
      "    import botocore.configloader\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/configloader.py\", line 19, in <module>\n",
      "    from botocore.compat import six\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/compat.py\", line 26, in <module>\n",
      "    from dateutil.tz import tzlocal\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/dateutil/tz/__init__.py\", line 2, in <module>\n",
      "    from .tz import *\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/dateutil/tz/tz.py\", line 1679, in <module>\n",
      "    gettz = __get_gettz()\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/dateutil/tz/tz.py\", line 1475, in __get_gettz\n",
      "    class GettzFunc(object):\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 6, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/env.py\", line 17, in <module>\n",
      "    from rasterio.session import Session, DummySession\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/session.py\", line 12, in <module>\n",
      "    import boto3\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/__init__.py\", line 16, in <module>\n",
      "    from boto3.session import Session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/session.py\", line 17, in <module>\n",
      "    import botocore.session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/session.py\", line 30, in <module>\n",
      "    import botocore.credentials\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/credentials.py\", line 26, in <module>\n",
      "    from dateutil.parser import parse\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/dateutil/parser/__init__.py\", line 2, in <module>\n",
      "    from ._parser import parse, parser, parserinfo, ParserError\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/dateutil/parser/_parser.py\", line 574, in <module>\n",
      "    class parser(object):\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/dateutil/parser/_parser.py\", line 1165, in parser\n",
      "    def _build_tzinfo(self, tzinfos, tzname, tzoffset):\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 6, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/env.py\", line 17, in <module>\n",
      "    from rasterio.session import Session, DummySession\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/session.py\", line 12, in <module>\n",
      "    import boto3\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/__init__.py\", line 16, in <module>\n",
      "    from boto3.session import Session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/session.py\", line 17, in <module>\n",
      "    import botocore.session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/session.py\", line 30, in <module>\n",
      "    import botocore.credentials\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/credentials.py\", line 34, in <module>\n",
      "    from botocore.config import Config\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/config.py\", line 16, in <module>\n",
      "    from botocore.endpoint import DEFAULT_TIMEOUT, MAX_POOL_CONNECTIONS\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/endpoint.py\", line 22, in <module>\n",
      "    from botocore.awsrequest import create_request_object\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/awsrequest.py\", line 26, in <module>\n",
      "    import botocore.utils\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/utils.py\", line 174, in <module>\n",
      "    IPV6_ADDRZ_RE = re.compile(\"^\" + IPV6_ADDRZ_PAT + \"$\")\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/re.py\", line 250, in compile\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/re.py\", line 302, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_compile.py\", line 764, in compile\n",
      "    p = sre_parse.parse(p, flags)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_parse.py\", line 948, in parse\n",
      "    p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_parse.py\", line 443, in _parse_sub\n",
      "    itemsappend(_parse(source, state, verbose, nested + 1,\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_parse.py\", line 834, in _parse\n",
      "    p = _parse_sub(source, state, sub_verbose, nested + 1)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_parse.py\", line 443, in _parse_sub\n",
      "    itemsappend(_parse(source, state, verbose, nested + 1,\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_parse.py\", line 834, in _parse\n",
      "    p = _parse_sub(source, state, sub_verbose, nested + 1)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_parse.py\", line 443, in _parse_sub\n",
      "    itemsappend(_parse(source, state, verbose, nested + 1,\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_parse.py\", line 641, in _parse\n",
      "    hi += sourceget()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_parse.py\", line 256, in get\n",
      "    self.__next()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_parse.py\", line 247, in __next\n",
      "    self.index = index + 1\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 6, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/env.py\", line 17, in <module>\n",
      "    from rasterio.session import Session, DummySession\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/session.py\", line 12, in <module>\n",
      "    import boto3\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/__init__.py\", line 16, in <module>\n",
      "    from boto3.session import Session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/session.py\", line 17, in <module>\n",
      "    import botocore.session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/session.py\", line 30, in <module>\n",
      "    import botocore.credentials\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/credentials.py\", line 26, in <module>\n",
      "    from dateutil.parser import parse\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/dateutil/parser/__init__.py\", line 2, in <module>\n",
      "    from ._parser import parse, parser, parserinfo, ParserError\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/dateutil/parser/_parser.py\", line 574, in <module>\n",
      "    class parser(object):\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/dateutil/parser/_parser.py\", line 1165, in parser\n",
      "    def _build_tzinfo(self, tzinfos, tzname, tzoffset):\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 6, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/env.py\", line 17, in <module>\n",
      "    from rasterio.session import Session, DummySession\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/session.py\", line 12, in <module>\n",
      "    import boto3\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/__init__.py\", line 16, in <module>\n",
      "    from boto3.session import Session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/session.py\", line 17, in <module>\n",
      "    import botocore.session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/session.py\", line 31, in <module>\n",
      "    import botocore.client\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/client.py\", line 16, in <module>\n",
      "    from botocore import waiter, xform_name\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/waiter.py\", line 18, in <module>\n",
      "    from botocore.docs.docstring import WaiterDocstring\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/docs/__init__.py\", line 15, in <module>\n",
      "    from botocore.docs.service import ServiceDocumenter\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 914, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1342, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1314, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1443, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1483, in _fill_cache\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/__init__.py\", line 4, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/__init__.py\", line 8, in <module>\n",
      "    import labelbox.schema.invite\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/invite.py\", line 5, in <module>\n",
      "    from labelbox.schema.role import ProjectRole, format_role\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/role.py\", line 6, in <module>\n",
      "    from labelbox.schema.project import Project\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/schema/project.py\", line 20, in <module>\n",
      "    from labelbox.data.serialization import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/__init__.py\", line 1, in <module>\n",
      "    from .labelbox_v1 import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/__init__.py\", line 1, in <module>\n",
      "    from .converter import LBV1Converter\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/converter.py\", line 11, in <module>\n",
      "    from .label import LBV1Label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/serialization/labelbox_v1/label.py\", line 6, in <module>\n",
      "    from ...annotation_types.annotation import (ClassificationAnnotation,\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/__init__.py\", line 1, in <module>\n",
      "    from .geometry import Line\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/__init__.py\", line 3, in <module>\n",
      "    from .mask import Mask\n",
      "  File \"/Users/matthewsokoloff/Projects/labelbox-python/labelbox/data/annotation_types/geometry/mask.py\", line 5, in <module>\n",
      "    from rasterio.features import shapes\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/__init__.py\", line 9, in <module>\n",
      "    from rasterio._base import gdal_version\n",
      "  File \"rasterio/_base.pyx\", line 1, in init rasterio._base\n",
      "  File \"rasterio/shim_rasterioex.pxi\", line 6, in init rasterio._shim\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/env.py\", line 17, in <module>\n",
      "    from rasterio.session import Session, DummySession\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/rasterio/session.py\", line 12, in <module>\n",
      "    import boto3\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/__init__.py\", line 16, in <module>\n",
      "    from boto3.session import Session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/boto3/session.py\", line 17, in <module>\n",
      "    import botocore.session\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/session.py\", line 31, in <module>\n",
      "    import botocore.client\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/client.py\", line 16, in <module>\n",
      "    from botocore import waiter, xform_name\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/waiter.py\", line 18, in <module>\n",
      "    from botocore.docs.docstring import WaiterDocstring\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/docs/__init__.py\", line 15, in <module>\n",
      "    from botocore.docs.service import ServiceDocumenter\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/docs/service.py\", line 19, in <module>\n",
      "    from botocore.docs.bcdoc.restdoc import DocumentStructure\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/docs/bcdoc/restdoc.py\", line 16, in <module>\n",
      "    from botocore.docs.bcdoc.docstringparser import DocStringParser\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/docs/bcdoc/docstringparser.py\", line 16, in <module>\n",
      "    class DocStringParser(six.moves.html_parser.HTMLParser):\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/vendored/six.py\", line 92, in __get__\n",
      "    result = self._resolve()\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/vendored/six.py\", line 115, in _resolve\n",
      "    return _import_module(self.mod)\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/botocore/vendored/six.py\", line 82, in _import_module\n",
      "    __import__(name)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/html/parser.py\", line 26, in <module>\n",
      "    charref = re.compile('&#(?:[0-9]+|[xX][0-9a-fA-F]+)[^0-9a-fA-F]')\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/re.py\", line 250, in compile\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/re.py\", line 302, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_compile.py\", line 768, in compile\n",
      "    code = _code(p, flags)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_compile.py\", line 607, in _code\n",
      "    _compile(code, p.data, flags)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_compile.py\", line 209, in _compile\n",
      "    _compile(code, av, flags)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_compile.py\", line 148, in _compile\n",
      "    _compile(code, av[2], flags)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_compile.py\", line 120, in _compile\n",
      "    charset, hascased = _optimize_charset(av, iscased, tolower, fixes)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/sre_compile.py\", line 366, in _optimize_charset\n",
      "    out += tail\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nt/wvdpx13s7hd7dwj64cdg9gkc0000gn/T/ipykernel_68821/2032963383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m coco = CocoInstanceDataset.from_common(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimage_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/labelbox-python/labelbox/data/serialization/coco/instance_dataset.py\u001b[0m in \u001b[0;36mfrom_common\u001b[0;34m(cls, labels, image_root)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/labelbox-python/labelbox/data/serialization/coco/instance_dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/labelbox-python/labelbox/data/annotation_types/collection.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mNone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthese\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0mdo\u001b[0m \u001b[0manything\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0monce\u001b[0m \u001b[0mso\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mminimal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/labelbox-python/labelbox/data/generator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompleted_threads\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: Make sure data exists...\n",
    "im_root = \"/tmp/images\"\n",
    "mask_root = \"/tmp/masks\"\n",
    "if not os.path.exists(im_root):\n",
    "    os.mkdir(im_root)\n",
    "\n",
    "if not os.path.exists(mask_root):\n",
    "    os.mkdir(mask_root)\n",
    "    \n",
    "coco = CocoInstanceDataset.from_common(\n",
    "    labels = labels, \n",
    "    image_root = im_root\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = coco.dict() # Remove this once we refresh the notebook\n",
    "n_classes = len({category['id'] for category in coco['categories']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = coco['images']\n",
    "import random\n",
    "random.shuffle(images)\n",
    "\n",
    "def get_annotations(images, all_annotations):\n",
    "    image_lookup = {image['id'] for image in images}\n",
    "    return [annot for annot in all_annotations if annot['image_id'] in image_lookup]\n",
    "\n",
    "\n",
    "train_partition = dict(\n",
    "    categories = coco['categories'],\n",
    "    images = images[:int(0.8 * len(images))],\n",
    "    annotations = get_annotations(images[:int(0.8 * len(images))], coco['annotations'])\n",
    ")\n",
    "                         \n",
    "\n",
    "                              \n",
    "test_partition = dict(\n",
    "    categories = coco['categories'],\n",
    "    images = images[int(0.8 * len(images)):],\n",
    "    annotations = get_annotations(images[int(0.8 * len(images)):], coco['annotations']) \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_path, test_ds_path = '/tmp/json_train_annotations.json', '/tmp/json_test_annotations.json'\n",
    "with open(train_ds_path, 'w') as file:\n",
    "    json.dump(train_partition, file)\n",
    "\n",
    "with open(test_ds_path, 'w') as file:\n",
    "    json.dump(test_partition, file)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "register_coco_instances(\"custom_coco_train\", {}, train_ds_path, im_root)\n",
    "register_coco_instances(\"custom_coco_test\", {}, test_ds_path, im_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets.coco import load_coco_json\n",
    "MetadataCatalog.get(\"custom_coco_test\").thing_classes = {r['id'] : r['name'] for r in coco['categories']}\n",
    "test_json = load_coco_json('/tmp/json_test_annotations.json', im_root)\n",
    "images = []\n",
    "import numpy as np\n",
    "for idx, example in enumerate(test_json):\n",
    "    if idx > 5:\n",
    "        break\n",
    "    \n",
    "    im = cv2.imread(example['file_name'])\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(\"custom_coco_test\"), scale=1.0)\n",
    "    out = v.draw_dataset_dict(example)\n",
    "    images.append(out.get_image())\n",
    "Image.fromarray(np.vstack(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"custom_coco_train\",)\n",
    "\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.MODEL.DEVICE = 'cpu'\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025 \n",
    "cfg.SOLVER.MAX_ITER = 20\n",
    "cfg.SOLVER.STEPS = []        \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = n_classes \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "\"\"\"\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluator = COCOEvaluator(\"custom_coco_test\")\n",
    "val_loader = build_detection_test_loader(cfg, \"custom_coco_test\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-terry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use `Visualizer` to draw the predictions on the image.\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "import numpy as np\n",
    "for idx, batch in enumerate(iter(val_loader)):\n",
    "    if idx > 3:\n",
    "        break\n",
    "    batch_inferences = []\n",
    "    for example in batch:\n",
    "        im = np.transpose(example['image'].numpy(), [1,2,0])\n",
    "        outputs = predictor(im)\n",
    "        v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        batch_inferences.append(out.get_image()[:, :, ::-1])\n",
    "    images.append(np.hstack(batch_inferences))\n",
    "Image.fromarray(np.vstack(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(\"custom_coco_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(\"custom_coco_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-barrier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-return",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-invite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-chapter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-bedroom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-james",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panoptic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confidential-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"ckputryh2000h0y8b65dfbo9r\" #\"ckq4q69ru004f0yah8sj289v2\"\n",
    "proj = client.get_project(project_id)\n",
    "labels = proj.label_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dirty-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:24,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Make sure data exists...\n",
    "im_root = \"/tmp/images\"\n",
    "mask_root = \"/tmp/masks\"\n",
    "if not os.path.exists(im_root):\n",
    "    os.mkdir(im_root)\n",
    "\n",
    "if not os.path.exists(mask_root):\n",
    "    os.mkdir(mask_root)\n",
    "    \n",
    "    \n",
    "lbls = []\n",
    "for idx, label in enumerate(labels):\n",
    "    lbls.append(label)\n",
    "    if idx > 10:\n",
    "        break\n",
    "        \n",
    "coco = CocoPanopticDataset.from_common(\n",
    "    labels = lbls, \n",
    "    image_root = im_root,\n",
    "    seg_root = mask_root\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aggregate-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = coco.dict() # Remove this once we refresh the notebook\n",
    "n_classes = len({category['id'] for category in coco['categories']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "postal-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = coco['images']\n",
    "import random\n",
    "random.shuffle(images)\n",
    "\n",
    "def get_annotations(images, all_annotations):\n",
    "    image_lookup = {image['id'] for image in images}\n",
    "    return [annot for annot in all_annotations if annot['image_id'] in image_lookup]\n",
    "\n",
    "\n",
    "train_partition = dict(\n",
    "    categories = coco['categories'],\n",
    "    images = images[:int(0.8 * len(images))],\n",
    "    annotations = get_annotations(images[:int(0.8 * len(images))], coco['annotations'])\n",
    ")\n",
    "                         \n",
    "\n",
    "                              \n",
    "test_partition = dict(\n",
    "    categories = coco['categories'],\n",
    "    images = images[int(0.8 * len(images)):],\n",
    "    annotations = get_annotations(images[int(0.8 * len(images)):], coco['annotations']) \n",
    ")\n",
    "\n",
    "train_ds_path, test_ds_path = '/tmp/json_train_annotations.json', '/tmp/json_test_annotations.json'\n",
    "with open(train_ds_path, 'w') as file:\n",
    "    json.dump(train_partition, file)\n",
    "\n",
    "with open(test_ds_path, 'w') as file:\n",
    "    json.dump(test_partition, file)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "continued-secret",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person', 1: 'car'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{r['id'] : r['name'] for r in coco['categories']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "particular-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_classes = ['car']\n",
    "thing_classes = ['person']\n",
    "stuff_dataset_id_to_contiguous_id = {0:0}\n",
    "thing_dataset_id_to_contiguous_id = {0:0}\n",
    "mmeta = {\n",
    "    'stuff_classes' : stuff_classes,\n",
    "    'thing_classes' : thing_classes,\n",
    "    'stuff_dataset_id_to_contiguous_id' : stuff_dataset_id_to_contiguous_id,\n",
    "    'thing_dataset_id_to_contiguous_id' : thing_dataset_id_to_contiguous_id\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mmeta = {'thing_dataset_id_to_contiguous_id' : {idx:0}}\n",
    "#indices = range(len({r['id'] : r['name'] for r in coco['categories']}))\n",
    "#mmeta.update({'stuff_dataset_id_to_contiguous_id' : {idx:idx for idx in indices if idx != 0}})\n",
    "#mmeta.update({'thing_classes' : list({r['name'] for r in coco['categories']})})\n",
    "#mmeta.update({'stuff_classes' : list({r['name'] for r in coco['categories']})})\n",
    "\n",
    "\n",
    "register_coco_panoptic(\"panoptic_train_6\", mmeta,im_root,  mask_root,train_ds_path)\n",
    "register_coco_panoptic(\"panoptic_test_6\", mmeta, im_root, mask_root,test_ds_path)\n",
    "\n",
    "# We need thing and stuff classes and we need to set the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "respected-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata(evaluator_type='coco_panoptic_seg', ignore_label=255, image_root='/tmp/images', json_file=None, label_divisor=1000, name='panoptic_test_6', panoptic_json='/tmp/json_test_annotations.json', panoptic_root='/tmp/segs', stuff_classes=['car'], stuff_dataset_id_to_contiguous_id={0: 0, 1: 1}, thing_classes=['person'], thing_dataset_id_to_contiguous_id={0: 0, 1: 1})\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'thing_dataset_id_to_contiguous_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nt/wvdpx13s7hd7dwj64cdg9gkc0000gn/T/ipykernel_68821/1476547666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco_panoptic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_coco_panoptic_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetadataCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"panoptic_test_6\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_coco_panoptic_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_root\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/detectron2/data/datasets/coco_panoptic.py\u001b[0m in \u001b[0;36mload_coco_panoptic_json\u001b[0;34m(json_file, image_dir, gt_dir, meta)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mlabel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0msegments_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert_category_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"segments_info\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         ret.append(\n\u001b[1;32m     53\u001b[0m             {\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/detectron2/data/datasets/coco_panoptic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mlabel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0msegments_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert_category_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"segments_info\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         ret.append(\n\u001b[1;32m     53\u001b[0m             {\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/detectron2/data/datasets/coco_panoptic.py\u001b[0m in \u001b[0;36m_convert_category_id\u001b[0;34m(segment_info, meta)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_category_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0msegment_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"thing_dataset_id_to_contiguous_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             segment_info[\"category_id\"] = meta[\"thing_dataset_id_to_contiguous_id\"][\n\u001b[1;32m     29\u001b[0m                 \u001b[0msegment_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"category_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'thing_dataset_id_to_contiguous_id'"
     ]
    }
   ],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets.coco import load_coco_json\n",
    "from detectron2.data.datasets.coco_panoptic import load_coco_panoptic_json\n",
    "print(MetadataCatalog.get(\"panoptic_test_6\"))\n",
    "test_json = load_coco_panoptic_json(test_ds_path, im_root, mask_root ,{})\n",
    "images = []\n",
    "import numpy as np\n",
    "for idx, example in enumerate(test_json):\n",
    "    if idx > 5:\n",
    "        break\n",
    "    \n",
    "    im = cv2.imread(example['file_name'])\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(\"panoptic_test_6\"), scale=1.0)\n",
    "    out = v.draw_dataset_dict(example)\n",
    "    images.append(out.get_image())\n",
    "Image.fromarray(np.vstack(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "frozen-nature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/01 23:08:14 d2.engine.defaults]: \u001b[0mModel:\n",
      "PanopticFPN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): SemSegFPNHead(\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (p5): Sequential(\n",
      "      (0): Conv2d(\n",
      "        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (2): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (4): Conv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (5): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    )\n",
      "    (predictor): Conv2d(128, 54, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/01 23:08:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/01 23:08:14 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/01 23:08:14 d2.data.common]: \u001b[0mSerializing 9 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/01 23:08:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"panoptic_train_6\",)\n",
    "\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.MODEL.DEVICE = 'cpu'\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025 \n",
    "cfg.SOLVER.MAX_ITER = 300\n",
    "cfg.SOLVER.STEPS = []        \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = n_classes \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "trainer = DefaultTrainer(cfg) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "representative-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/01 23:08:14 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[08/01 23:08:26 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/detectron2/engine/train_loop.py\", line 149, in train\n",
      "    self.run_step()\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/detectron2/engine/defaults.py\", line 499, in run_step\n",
      "    self._trainer.run_step()\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/detectron2/engine/train_loop.py\", line 273, in run_step\n",
      "    loss_dict = self.model(data)\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/matthewsokoloff/Library/Python/3.8/lib/python/site-packages/detectron2/modeling/meta_arch/panoptic_fpn.py\", line 119, in forward\n",
      "    assert \"sem_seg\" in batched_inputs[0]\n",
      "AssertionError\n",
      "\u001b[32m[08/01 23:08:26 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:12 (0:00:00 on hooks)\n",
      "\u001b[32m[08/01 23:08:26 d2.utils.events]: \u001b[0m iter: 0    lr: N/A  \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nt/wvdpx13s7hd7dwj64cdg9gkc0000gn/T/ipykernel_68821/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             assert hasattr(\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# self.iter == max_iter can be used by `after_train` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0msomething\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \"\"\"\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/detectron2/modeling/meta_arch/panoptic_fpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;34m\"sem_seg\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mgt_sem_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sem_seg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         gt_sem_seg = ImageList.from_tensors(\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/cocodataset/panopticapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "little-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from fvcore.common.download import download\n",
    "from panopticapi.utils import rgb2id\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _process_panoptic_to_semantic(input_panoptic, output_semantic, segments, id_map):\n",
    "    panoptic = np.asarray(Image.open(input_panoptic), dtype=np.uint32)\n",
    "    panoptic = rgb2id(panoptic)\n",
    "    output = np.zeros_like(panoptic, dtype=np.uint8) + 255\n",
    "    for seg in segments:\n",
    "        cat_id = seg[\"category_id\"]\n",
    "        new_cat_id = id_map[cat_id]\n",
    "        output[panoptic == seg[\"id\"]] = new_cat_id\n",
    "    Image.fromarray(output).save(output_semantic)\n",
    "\n",
    "\n",
    "def separate_coco_semantic_from_panoptic(panoptic_json, panoptic_root, sem_seg_root, categories):\n",
    "    \"\"\"\n",
    "    Create semantic segmentation annotations from panoptic segmentation\n",
    "    annotations, to be used by PanopticFPN.\n",
    "    It maps all thing categories to class 0, and maps all unlabeled pixels to class 255.\n",
    "    It maps all stuff categories to contiguous ids starting from 1.\n",
    "    Args:\n",
    "        panoptic_json (str): path to the panoptic json file, in COCO's format.\n",
    "        panoptic_root (str): a directory with panoptic annotation files, in COCO's format.\n",
    "        sem_seg_root (str): a directory to output semantic annotation files\n",
    "        categories (list[dict]): category metadata. Each dict needs to have:\n",
    "            \"id\": corresponds to the \"category_id\" in the json annotations\n",
    "            \"isthing\": 0 or 1\n",
    "    \"\"\"\n",
    "    os.makedirs(sem_seg_root, exist_ok=True)\n",
    "\n",
    "    stuff_ids = [k[\"id\"] for k in categories] # if k[\"isthing\"] == 0]\n",
    "    thing_ids = [] #[k[\"id\"] for k in categories if k[\"isthing\"] == 1]\n",
    "    id_map = {}  # map from category id to id in the output semantic annotation\n",
    "    assert len(stuff_ids) <= 254\n",
    "    for i, stuff_id in enumerate(stuff_ids):\n",
    "        id_map[stuff_id] = i + 1\n",
    "    for thing_id in thing_ids:\n",
    "        id_map[thing_id] = 0\n",
    "    id_map[0] = 255\n",
    "\n",
    "    with open(panoptic_json) as f:\n",
    "        obj = json.load(f)\n",
    "\n",
    "\n",
    "    def iter_annotations():\n",
    "        for anno in obj[\"annotations\"]:\n",
    "            file_name = anno[\"file_name\"]\n",
    "            segments = anno[\"segments_info\"]\n",
    "            input = os.path.join(panoptic_root, file_name)\n",
    "            output = os.path.join(sem_seg_root, file_name)\n",
    "            yield input, output, segments\n",
    "\n",
    "    print(\"Start writing to {} ...\".format(sem_seg_root))\n",
    "    start = time.time()\n",
    "    for i,o,s in iter_annotations():\n",
    "        _process_panoptic_to_semantic(i,o,s, id_map)\n",
    "    print(\"Finished. time: {:.2f}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "respective-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'name': 'person', 'supercategory': 'all', 'isthing': 0},\n",
       " {'id': 1, 'name': 'car', 'supercategory': 'all', 'isthing': 0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fluid-minimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start writing to /tmp/segs ...\n",
      "Finished. time: 0.12s\n"
     ]
    }
   ],
   "source": [
    "separate_coco_semantic_from_panoptic(train_ds_path, mask_root, \"/tmp/segs\", coco['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "metric-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_panoptic(\"panoptic_train_6\", mmeta,im_root,  \"/tmp/segs\",train_ds_path)\n",
    "register_coco_panoptic(\"panoptic_test_6\", mmeta, im_root, \"/tmp/segs\",test_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-messenger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_panoptic_separated('panoptic_train_6', mmeta, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
