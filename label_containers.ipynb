{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solid-valve",
   "metadata": {},
   "source": [
    "# Label Containers\n",
    "* There are two high level containers for labels\n",
    "    1. LabelCollection\n",
    "    2. LabelGenerator\n",
    "* Tools that are built to convert between formats, help with etl, and model training all will operate on these containers\n",
    "* Make sure to read basics. Explanations are not repeated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import labelbox\n",
    "except: \n",
    "    !git clone https://github.com/Labelbox/labelbox-python.git\n",
    "    !cd labelbox-python && git checkout ms/annotation-examples && pip install .[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelbox import Client\n",
    "from labelbox.data.annotation_types import LabelCollection, LabelGenerator\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
    "from labelbox import LabelingFrontend\n",
    "from labelbox.data.annotation_types import (\n",
    "    Label, \n",
    "    RasterData, \n",
    "    Mask, \n",
    "    Point, \n",
    "    Polygon, \n",
    "    ClassificationAnswer, \n",
    "    Radio, \n",
    "    Checklist, \n",
    "    ObjectAnnotation, \n",
    "    ClassificationAnnotation\n",
    ")\n",
    "from getpass import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't want to give google access to drive you can skip this cell\n",
    "# and manually set `API_KEY` below.\n",
    "COLAB = \"google.colab\" in str(get_ipython())\n",
    "if COLAB:\n",
    "    !pip install colab-env -qU\n",
    "    from colab_env import envvar_handler\n",
    "    envvar_handler.envload()\n",
    "\n",
    "API_KEY = os.environ.get(\"LABELBOX_API_KEY\")\n",
    "if not os.environ.get(\"LABELBOX_API_KEY\"):\n",
    "    API_KEY = getpass(\"Please enter your labelbox api key\")\n",
    "    if COLAB:\n",
    "        envvar_handler.add_env(\"LABELBOX_API_KEY\", API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only update this if you have an on-prem deployment\n",
    "ENDPOINT = \"https://api.labelbox.com/graphql\"\n",
    "\n",
    "client = Client(api_key=API_KEY, endpoint=ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-course",
   "metadata": {},
   "source": [
    "#### Helper Functions\n",
    "* See annotation_type_basics for details on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signing_function(obj_bytes: bytes) -> str:\n",
    "    # Do not use this signer. You will not be able to resign these images at a later date.\n",
    "    url = client.upload_data(content=obj_bytes, sign=True)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon():\n",
    "    # Given some polygon:\n",
    "    xy_poly = [\n",
    "        [60, 161], [67, 177], [76, 180], [77, 222], [82, 246], [78, 291], [72, 300], [87, 300], \n",
    "        [94, 244], [103, 243], [100, 269], [90, 290], [95, 296], [104, 292], [108, 272], \n",
    "        [111, 300], [121, 300], [117, 244], [128, 236], [133, 298], [142, 297], [137, 250], \n",
    "        [146, 208], [138, 185], [120, 180], [105, 189], [112, 162], [93, 156], [72, 160], \n",
    "    ]\n",
    "    return Polygon(points = [Point(x = x, y = y) for x,y in xy_poly])\n",
    "\n",
    "\n",
    "def get_labels():\n",
    "    im_h, im_w = 300, 200\n",
    "    image_url = \"https://picsum.photos/id/1003/200/300\"\n",
    "    nose_color, eye_color = 128, 255\n",
    "    nose_mask = Point(x = 96, y = 194).raster(im_h, im_w, thickness = 3)\n",
    "    eye_masks = [\n",
    "         Point(x = 84, y = 182).raster(im_h, im_w, thickness = 3),\n",
    "        Point(x = 99, y = 181).raster(im_h, im_w, thickness = 3),\n",
    "    ]\n",
    "    mask_arr = np.max([*eye_masks,nose_mask] , axis = 0)\n",
    "    mask = RasterData(arr = mask_arr)\n",
    "    return [Label(\n",
    "        data = RasterData(im_bytes = requests.get(image_url).content),\n",
    "        annotations = [\n",
    "            ObjectAnnotation(value = get_polygon(),name = \"deer\"),\n",
    "            ObjectAnnotation(name = \"deer_eyes\", value = Mask(mask = mask, color = eye_color)),  \n",
    "            ObjectAnnotation(name = \"deer_nose\", value = Mask(mask = mask, color = nose_color),\n",
    "                classifications = [\n",
    "                    ClassificationAnnotation(\n",
    "                        name = \"nose_description\",\n",
    "                        value = Radio(\n",
    "                            answer = ClassificationAnswer(name = \"wet\")\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            ClassificationAnnotation(name = \"image_description\", value = Checklist(answer = [\n",
    "                ClassificationAnswer(name = \"bright\")\n",
    "            ]))\n",
    "        ]\n",
    "    )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_schema_ids(label):\n",
    "    for annotation in label.annotations:\n",
    "        print(f\"Object : {annotation.name} - {annotation.schema_id}\")\n",
    "        for classification in annotation.classifications:\n",
    "            print(f\"--- Subclass : {classification.name} - {classification.schema_id}\")\n",
    "            option = classification.value\n",
    "            print(f\"--- --- Options: {option.answer.name} - {option.answer.schema_id}\")\n",
    "\n",
    "        if isinstance(annotation, ClassificationAnnotation):\n",
    "            for option in annotation.value.answer:\n",
    "                print(f\"--- Options: {option.name} - {option.schema_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_project():\n",
    "    # These names have to match our object names exactly!!\n",
    "    ontology_builder = OntologyBuilder(tools=[\n",
    "        Tool(tool=Tool.Type.POLYGON, name=\"deer\"),\n",
    "        Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_nose\", \n",
    "             classifications = [\n",
    "                 Classification(\n",
    "                     class_type = Classification.Type.RADIO, \n",
    "                     instructions = \"nose_description\", \n",
    "                     options = [Option(value = \"wet\")]\n",
    "                 )]),\n",
    "        Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_eyes\")    \n",
    "    ], classifications = [\n",
    "        Classification(\n",
    "            Classification.Type.CHECKLIST, \n",
    "            instructions = \"image_description\", \n",
    "            options = [Option(value = \"bright\"), Option(value = \"not_blurry\"), Option(value = \"dark\")])])\n",
    "\n",
    "    editor = next(\n",
    "        client.get_labeling_frontends(where=LabelingFrontend.name == \"Editor\"))\n",
    "    project = client.create_project(name=\"test_annotation_types\")\n",
    "    project.setup(editor, ontology_builder.asdict())\n",
    "    dataset = client.create_dataset(name = 'my_ds')\n",
    "    project.datasets.connect(dataset)\n",
    "\n",
    "    ontology = OntologyBuilder.from_project(project)\n",
    "    return ontology, dataset, project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mask_urls(label):\n",
    "    for annotation in label.annotations:\n",
    "        if isinstance(annotation.value, Mask):\n",
    "            print(annotation.value.mask.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_references(label):\n",
    "    print('\\n---  schema ids ---\\n')\n",
    "    show_schema_ids(label)\n",
    "    print(\"\\n--- mask urls ---\\n\")\n",
    "    print_mask_urls(label)\n",
    "    print('\\n--- image url ---\\n')\n",
    "    print(label.data.url)    \n",
    "    print('\\n--- data row reference ---\\n')\n",
    "    print(original_label.data.uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-absorption",
   "metadata": {},
   "source": [
    "# LabelCollection\n",
    "* This object is essentially a list of Labels with a set of helpful utilties\n",
    "* This object is simple and fast at the expense of memory\n",
    "    * Larger datasets shouldn't use label collections ( or at least will require more ram ).\n",
    "* Why use label collection over just a list of labels?\n",
    "    * Multithreaded utilities (faster)\n",
    "    * Compatible with converter functions (functions useful for translating between formats, etl, and training )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels()\n",
    "label_collection = LabelCollection(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-tiger",
   "metadata": {},
   "source": [
    "## Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterable, behaves like a list\n",
    "for label in label_collection:\n",
    "    print(type(label))\n",
    "# Get length\n",
    "print(len(label_collection))\n",
    "# By index\n",
    "print(type(label_collection[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-ready",
   "metadata": {},
   "source": [
    "### Upload segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add urls to all segmentation masks:\n",
    "# (in parallel)\n",
    "for label in label_collection:\n",
    "    print_mask_urls(label)\n",
    "    \n",
    "label_collection.add_url_to_masks(signing_function)\n",
    "\n",
    "for label in label_collection:\n",
    "    print_mask_urls(label)\n",
    "# Again note that these all share the same segmentation mask\n",
    "# ( This is determined by the fact that they share the same reference )\n",
    "# This mask is only uploaded once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-routine",
   "metadata": {},
   "source": [
    "### Create signed urls for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add urls to all segmentation masks:\n",
    "# (in parallel)\n",
    "print(label_collection[0].data.url)\n",
    "label_collection.add_url_to_data(signing_function)\n",
    "print(label_collection[0].data.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-partnership",
   "metadata": {},
   "source": [
    "### Add to labelbox dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next two sections we need an ontology and dataset\n",
    "ontology, dataset, project = setup_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_collection[0].data.uid)\n",
    "# Note that this function will assign a uuid as the external id if it isn't provided.\n",
    "label_collection.add_to_dataset(dataset, signing_function)\n",
    "print(label_collection[0].data.uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-public",
   "metadata": {},
   "source": [
    "### Add schema ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in label_collection:\n",
    "    show_schema_ids(label)\n",
    "# Note that this function will assign a uuid as the external id if it isn't provided.\n",
    "label_collection.assign_schema_ids(ontology)\n",
    "print('-'* 50)\n",
    "for label in label_collection:\n",
    "    show_schema_ids(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup:\n",
    "dataset.delete()\n",
    "project.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-invite",
   "metadata": {},
   "source": [
    "# LabelGenerator\n",
    "* This object generates labels and provides a set of helpful utilties\n",
    "* This object is complex and slower than LabelCollections in order to be highly memory efficient\n",
    "    * Larger datasets should use label generators\n",
    "* Why use label generator over just a generator that yields labels?\n",
    "    * This object supports parallel io operations to buffer results in the background.\n",
    "    * Compatible with converter functions (functions useful for translating between formats, etl, and training )\n",
    "* The first qsize elements run serially from when the chained functions are added.\n",
    "    * After that iterating will get much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels()\n",
    "label_generator = LabelGenerator(labels)\n",
    "ontology, dataset, project = setup_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can't show the before and afters because the generator is not repeatable\n",
    "\n",
    "try:\n",
    "    label = next(label_generator)\n",
    "    print(\"Ran once\")\n",
    "    label = next(label_generator)\n",
    "    print(\"Ran twice\")\n",
    "except StopIteration:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not support indexing ( it is a generator.. )\n",
    "try:\n",
    "    label_generator[0]\n",
    "    print(\"Can index\")\n",
    "except TypeError:\n",
    "    print(\"Unable to index\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-antenna",
   "metadata": {},
   "source": [
    "### Functions to modify results\n",
    "* We can set functions to run on the result of the generator\n",
    "* Since these are run in background threads it is a lot faster than applying them on each label individually\n",
    "* The functions are lazily evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate because we already went through all of the items when we showed that it isn't repeatable\n",
    "original_label = labels[0]\n",
    "\n",
    "show_references(original_label)\n",
    "label_generator = LabelGenerator(labels) \\\n",
    "        .add_url_to_masks(signing_function) \\\n",
    "        .add_to_dataset(dataset, signing_function) \\\n",
    "        .assign_schema_ids(ontology)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_references(original_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = next(label_generator)\n",
    "show_references(original_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-alpha",
   "metadata": {},
   "source": [
    "* Note that the first qsize elements run serially from when the chained functions are added.\n",
    "* After that iterating will get much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators can be converted to Collections\n",
    "LabelGenerator(labels).as_collection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.delete()\n",
    "project.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
